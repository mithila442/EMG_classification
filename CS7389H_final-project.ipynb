{
  "cells": [
    {
      "cell_type": "raw",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "collapsed": false,
        "id": "87187d23c9094ed8"
      },
      "id": "87187d23c9094ed8"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class EMGDataset(Dataset):\n",
        "    def __init__(self, data_directory, test_split=0.2, random_seed=100, sequence_length=500):\n",
        "        self.data_directory = data_directory\n",
        "        self.test_split = test_split\n",
        "        self.random_seed = random_seed\n",
        "        self.sequence_length = sequence_length\n",
        "        self.sequences = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Load and preprocess data\n",
        "        self.load_data()\n",
        "\n",
        "    def load_data(self):\n",
        "        scaler = StandardScaler()  # Initialize the scaler\n",
        "        step_size = 250  # Half the sequence_length for 50% overlap\n",
        "\n",
        "        for folder_name in os.listdir(self.data_directory):\n",
        "            folder_path = os.path.join(self.data_directory, folder_name)\n",
        "            if os.path.isdir(folder_path):\n",
        "                for file_name in os.listdir(folder_path):\n",
        "                    file_path = os.path.join(folder_path, file_name)\n",
        "                    data = np.loadtxt(file_path, delimiter='\\t', skiprows=1)\n",
        "\n",
        "                    # Normalize EMG data except for the label column\n",
        "                    data[:, 1:-1] = scaler.fit_transform(data[:, 1:-1])\n",
        "\n",
        "                    # Segment data into overlapping uniform sequences\n",
        "                    for start in range(0, len(data) - self.sequence_length + 1, step_size):\n",
        "                        end = start + self.sequence_length\n",
        "                        if end <= len(data):\n",
        "                            segment = data[start:end]\n",
        "                            self.sequences.append(segment[:, 1:-1])  # Exclude the first column if it's a timestamp\n",
        "                            self.labels.append(segment[0, -1])  # Use the label of the first row in the segment\n",
        "\n",
        "        self.labels = np.array(self.labels, dtype=int)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Convert sequences to tensor\n",
        "        sequence = torch.tensor(self.sequences[idx], dtype=torch.float32)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return sequence, label\n",
        "\n",
        "    def split_data(self):\n",
        "        indices = list(range(len(self)))\n",
        "        train_indices, test_indices = train_test_split(indices, test_size=self.test_split, random_state=self.random_seed)\n",
        "        train_data = [self[i] for i in train_indices]\n",
        "        test_data = [self[i] for i in test_indices]\n",
        "        return train_data, test_data\n",
        "\n",
        "# Example of how to use the EMGDataset class\n",
        "if __name__ == \"__main__\":\n",
        "    dataset = EMGDataset('./EMG_Data')\n",
        "    train_data, test_data = dataset.split_data()\n",
        "    print(f\"Number of training samples: {len(train_data)}\")\n",
        "    print(f\"Number of testing samples: {len(test_data)}\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-29T01:09:09.426092600Z",
          "start_time": "2024-04-29T01:09:04.464778900Z"
        },
        "id": "32840006eb5dd957",
        "outputId": "0a17ab65-c854-49bb-afc2-1c4d7726ade6"
      },
      "id": "32840006eb5dd957",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training samples: 13475\n",
            "Number of testing samples: 3369\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "910259a185139582"
      },
      "cell_type": "markdown",
      "source": [
        "LSTM model"
      ],
      "id": "910259a185139582"
    },
    {
      "metadata": {
        "id": "b3ee6efbabf8dcf"
      },
      "cell_type": "markdown",
      "source": [],
      "id": "b3ee6efbabf8dcf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Epoch 1: Training Loss = 1.9911, Training Accuracy = 19.75%\n",
            "Epoch 1: Validation Loss = 2.1383, Validation Accuracy = 15.80%\n",
            "Epoch 2: Training Loss = 1.7820, Training Accuracy = 16.76%\n",
            "Epoch 2: Validation Loss = 1.7267, Validation Accuracy = 23.99%\n",
            "Epoch 3: Training Loss = 1.4874, Training Accuracy = 23.35%\n",
            "Epoch 3: Validation Loss = 1.5449, Validation Accuracy = 27.73%\n",
            "Epoch 4: Training Loss = 1.4738, Training Accuracy = 25.30%\n",
            "Epoch 4: Validation Loss = 1.5133, Validation Accuracy = 29.45%\n",
            "Epoch 5: Training Loss = 1.3015, Training Accuracy = 29.24%\n",
            "Epoch 5: Validation Loss = 1.5197, Validation Accuracy = 30.46%\n",
            "Epoch 6: Training Loss = 1.1947, Training Accuracy = 30.64%\n",
            "Epoch 6: Validation Loss = 1.4179, Validation Accuracy = 32.07%\n",
            "Epoch 7: Training Loss = 1.1230, Training Accuracy = 31.50%\n",
            "Epoch 7: Validation Loss = 1.3990, Validation Accuracy = 33.55%\n",
            "Epoch 8: Training Loss = 1.1228, Training Accuracy = 33.40%\n",
            "Epoch 8: Validation Loss = 1.5341, Validation Accuracy = 33.85%\n",
            "Epoch 9: Training Loss = 1.0993, Training Accuracy = 37.53%\n",
            "Epoch 9: Validation Loss = 1.3170, Validation Accuracy = 43.41%\n",
            "Epoch 10: Training Loss = 1.0247, Training Accuracy = 38.78%\n",
            "Epoch 10: Validation Loss = 1.3333, Validation Accuracy = 40.97%\n",
            "Epoch 11: Training Loss = 0.9238, Training Accuracy = 40.81%\n",
            "Epoch 11: Validation Loss = 1.3260, Validation Accuracy = 39.37%\n",
            "Epoch 12: Training Loss = 0.8665, Training Accuracy = 40.53%\n",
            "Epoch 12: Validation Loss = 1.2591, Validation Accuracy = 43.76%\n",
            "Epoch 13: Training Loss = 0.8385, Training Accuracy = 42.69%\n",
            "Epoch 13: Validation Loss = 1.2333, Validation Accuracy = 44.00%\n",
            "Epoch 14: Training Loss = 1.0014, Training Accuracy = 39.88%\n",
            "Epoch 14: Validation Loss = 1.3792, Validation Accuracy = 38.90%\n",
            "Epoch 15: Training Loss = 0.8969, Training Accuracy = 41.27%\n",
            "Epoch 15: Validation Loss = 1.3096, Validation Accuracy = 45.43%\n",
            "Epoch 16: Training Loss = 0.7885, Training Accuracy = 44.52%\n",
            "Epoch 16: Validation Loss = 1.2627, Validation Accuracy = 45.07%\n",
            "Epoch 17: Training Loss = 0.7275, Training Accuracy = 46.29%\n",
            "Epoch 17: Validation Loss = 1.3642, Validation Accuracy = 42.34%\n",
            "Epoch 18: Training Loss = 0.7244, Training Accuracy = 45.76%\n",
            "Epoch 18: Validation Loss = 1.2946, Validation Accuracy = 45.13%\n",
            "Epoch 19: Training Loss = 0.7627, Training Accuracy = 44.55%\n",
            "Epoch 19: Validation Loss = 1.3025, Validation Accuracy = 43.29%\n",
            "Epoch 20: Training Loss = 0.7292, Training Accuracy = 44.19%\n",
            "Epoch 20: Validation Loss = 1.2018, Validation Accuracy = 45.84%\n",
            "Epoch 21: Training Loss = 0.7039, Training Accuracy = 45.97%\n",
            "Epoch 21: Validation Loss = 1.2516, Validation Accuracy = 46.62%\n",
            "Epoch 22: Training Loss = 0.6583, Training Accuracy = 46.60%\n",
            "Epoch 22: Validation Loss = 1.2825, Validation Accuracy = 44.83%\n",
            "Epoch 23: Training Loss = 0.7684, Training Accuracy = 41.45%\n",
            "Epoch 23: Validation Loss = 1.2611, Validation Accuracy = 43.35%\n",
            "Epoch 24: Training Loss = 1.1293, Training Accuracy = 31.90%\n",
            "Epoch 24: Validation Loss = 1.5162, Validation Accuracy = 29.63%\n",
            "Epoch 25: Training Loss = 0.9198, Training Accuracy = 35.94%\n",
            "Epoch 25: Validation Loss = 1.3858, Validation Accuracy = 38.84%\n",
            "Epoch 26: Training Loss = 0.7411, Training Accuracy = 41.41%\n",
            "Epoch 26: Validation Loss = 1.1366, Validation Accuracy = 47.27%\n",
            "Epoch 27: Training Loss = 0.7490, Training Accuracy = 43.61%\n",
            "Epoch 27: Validation Loss = 1.1839, Validation Accuracy = 48.57%\n",
            "Epoch 28: Training Loss = 0.6840, Training Accuracy = 47.22%\n",
            "Epoch 28: Validation Loss = 1.2019, Validation Accuracy = 46.91%\n",
            "Epoch 29: Training Loss = 0.6511, Training Accuracy = 48.67%\n",
            "Epoch 29: Validation Loss = 1.1449, Validation Accuracy = 47.98%\n",
            "Epoch 30: Training Loss = 0.6151, Training Accuracy = 49.65%\n",
            "Epoch 30: Validation Loss = 1.1527, Validation Accuracy = 50.59%\n",
            "Epoch 31: Training Loss = 0.6515, Training Accuracy = 45.91%\n",
            "Epoch 31: Validation Loss = 1.2516, Validation Accuracy = 43.11%\n",
            "Epoch 32: Training Loss = 0.6489, Training Accuracy = 43.53%\n",
            "Epoch 32: Validation Loss = 1.1723, Validation Accuracy = 46.02%\n",
            "Epoch 33: Training Loss = 0.6402, Training Accuracy = 44.48%\n",
            "Epoch 33: Validation Loss = 1.2060, Validation Accuracy = 45.55%\n",
            "Epoch 34: Training Loss = 0.5943, Training Accuracy = 47.13%\n",
            "Epoch 34: Validation Loss = 1.0924, Validation Accuracy = 50.83%\n",
            "Epoch 35: Training Loss = 0.5770, Training Accuracy = 49.68%\n",
            "Epoch 35: Validation Loss = 1.2244, Validation Accuracy = 47.27%\n",
            "Epoch 36: Training Loss = 0.5558, Training Accuracy = 50.15%\n",
            "Epoch 36: Validation Loss = 1.1253, Validation Accuracy = 50.24%\n",
            "Epoch 37: Training Loss = 0.5385, Training Accuracy = 51.26%\n",
            "Epoch 37: Validation Loss = 1.1308, Validation Accuracy = 50.12%\n",
            "Epoch 38: Training Loss = 0.5211, Training Accuracy = 51.55%\n",
            "Epoch 38: Validation Loss = 1.1161, Validation Accuracy = 50.18%\n",
            "Epoch 39: Training Loss = 0.5212, Training Accuracy = 51.36%\n",
            "Epoch 39: Validation Loss = 1.1398, Validation Accuracy = 51.07%\n",
            "Epoch 40: Training Loss = 0.4952, Training Accuracy = 52.07%\n",
            "Epoch 40: Validation Loss = 1.0895, Validation Accuracy = 50.89%\n",
            "Epoch 41: Training Loss = 0.4875, Training Accuracy = 52.30%\n",
            "Epoch 41: Validation Loss = 1.0120, Validation Accuracy = 52.91%\n",
            "Epoch 42: Training Loss = 0.5234, Training Accuracy = 51.78%\n",
            "Epoch 42: Validation Loss = 1.0692, Validation Accuracy = 53.09%\n",
            "Epoch 43: Training Loss = 0.4820, Training Accuracy = 52.53%\n",
            "Epoch 43: Validation Loss = 1.0637, Validation Accuracy = 51.07%\n",
            "Epoch 44: Training Loss = 0.4717, Training Accuracy = 52.82%\n",
            "Epoch 44: Validation Loss = 1.1264, Validation Accuracy = 51.72%\n",
            "Epoch 45: Training Loss = 0.5135, Training Accuracy = 51.35%\n",
            "Epoch 45: Validation Loss = 1.0614, Validation Accuracy = 53.09%\n",
            "Epoch 46: Training Loss = 0.4539, Training Accuracy = 54.05%\n",
            "Epoch 46: Validation Loss = 1.0766, Validation Accuracy = 52.73%\n",
            "Epoch 47: Training Loss = 0.4459, Training Accuracy = 53.91%\n",
            "Epoch 47: Validation Loss = 1.1115, Validation Accuracy = 52.73%\n",
            "Epoch 48: Training Loss = 0.4534, Training Accuracy = 53.55%\n",
            "Epoch 48: Validation Loss = 1.0828, Validation Accuracy = 54.04%\n",
            "Epoch 49: Training Loss = 0.4414, Training Accuracy = 53.87%\n",
            "Epoch 49: Validation Loss = 1.1587, Validation Accuracy = 49.11%\n",
            "Epoch 50: Training Loss = 0.4158, Training Accuracy = 54.60%\n",
            "Epoch 50: Validation Loss = 1.1425, Validation Accuracy = 51.66%\n",
            "Epoch 51: Training Loss = 0.4666, Training Accuracy = 52.47%\n",
            "Epoch 51: Validation Loss = 1.0586, Validation Accuracy = 53.09%\n",
            "Epoch 52: Training Loss = 0.4336, Training Accuracy = 54.49%\n",
            "Epoch 52: Validation Loss = 1.1714, Validation Accuracy = 49.88%\n",
            "Epoch 53: Training Loss = 0.4693, Training Accuracy = 52.96%\n",
            "Epoch 53: Validation Loss = 1.0650, Validation Accuracy = 55.17%\n",
            "Epoch 54: Training Loss = 0.3976, Training Accuracy = 55.34%\n",
            "Epoch 54: Validation Loss = 1.2018, Validation Accuracy = 47.57%\n",
            "Epoch 55: Training Loss = 0.3934, Training Accuracy = 54.64%\n",
            "Epoch 55: Validation Loss = 1.1003, Validation Accuracy = 53.68%\n",
            "Epoch 56: Training Loss = 0.3840, Training Accuracy = 55.18%\n",
            "Epoch 56: Validation Loss = 1.1299, Validation Accuracy = 52.14%\n",
            "Epoch 57: Training Loss = 0.4015, Training Accuracy = 56.19%\n",
            "Epoch 57: Validation Loss = 1.1779, Validation Accuracy = 48.57%\n",
            "Epoch 58: Training Loss = 0.3920, Training Accuracy = 55.29%\n",
            "Epoch 58: Validation Loss = 1.0931, Validation Accuracy = 53.21%\n",
            "Epoch 59: Training Loss = 0.3774, Training Accuracy = 55.84%\n",
            "Epoch 59: Validation Loss = 1.1123, Validation Accuracy = 53.74%\n",
            "Epoch 60: Training Loss = 0.3824, Training Accuracy = 56.16%\n",
            "Epoch 60: Validation Loss = 1.1141, Validation Accuracy = 52.73%\n",
            "Epoch 61: Training Loss = 0.3735, Training Accuracy = 55.99%\n",
            "Epoch 61: Validation Loss = 0.9499, Validation Accuracy = 55.94%\n",
            "Epoch 62: Training Loss = 0.3559, Training Accuracy = 56.36%\n",
            "Epoch 62: Validation Loss = 1.0997, Validation Accuracy = 53.80%\n",
            "Epoch 63: Training Loss = 0.3676, Training Accuracy = 56.74%\n",
            "Epoch 63: Validation Loss = 1.0664, Validation Accuracy = 54.63%\n",
            "Epoch 64: Training Loss = 0.3983, Training Accuracy = 56.27%\n",
            "Epoch 64: Validation Loss = 1.0749, Validation Accuracy = 53.03%\n",
            "Epoch 65: Training Loss = 0.3474, Training Accuracy = 57.25%\n",
            "Epoch 65: Validation Loss = 1.0468, Validation Accuracy = 53.86%\n",
            "Epoch 66: Training Loss = 0.3443, Training Accuracy = 56.46%\n",
            "Epoch 66: Validation Loss = 1.0455, Validation Accuracy = 54.39%\n",
            "Epoch 67: Training Loss = 0.3329, Training Accuracy = 57.74%\n",
            "Epoch 67: Validation Loss = 0.9607, Validation Accuracy = 56.47%\n",
            "Epoch 68: Training Loss = 0.3308, Training Accuracy = 58.56%\n",
            "Epoch 68: Validation Loss = 1.0840, Validation Accuracy = 54.22%\n",
            "Epoch 69: Training Loss = 0.3137, Training Accuracy = 58.76%\n",
            "Epoch 69: Validation Loss = 1.0817, Validation Accuracy = 53.38%\n",
            "Epoch 70: Training Loss = 0.3234, Training Accuracy = 58.61%\n",
            "Epoch 70: Validation Loss = 1.1135, Validation Accuracy = 53.03%\n",
            "Epoch 71: Training Loss = 0.3769, Training Accuracy = 57.62%\n",
            "Epoch 71: Validation Loss = 0.9870, Validation Accuracy = 57.30%\n",
            "Epoch 72: Training Loss = 0.3268, Training Accuracy = 59.12%\n",
            "Epoch 72: Validation Loss = 1.1271, Validation Accuracy = 52.32%\n",
            "Epoch 73: Training Loss = 0.3481, Training Accuracy = 57.74%\n",
            "Epoch 73: Validation Loss = 1.0341, Validation Accuracy = 54.51%\n",
            "Epoch 74: Training Loss = 0.3124, Training Accuracy = 59.59%\n",
            "Epoch 74: Validation Loss = 1.0844, Validation Accuracy = 54.57%\n",
            "Epoch 75: Training Loss = 0.3747, Training Accuracy = 58.06%\n",
            "Epoch 75: Validation Loss = 0.9990, Validation Accuracy = 55.23%\n",
            "Epoch 76: Training Loss = 0.3399, Training Accuracy = 59.47%\n",
            "Epoch 76: Validation Loss = 1.0626, Validation Accuracy = 55.70%\n",
            "Epoch 77: Training Loss = 0.3336, Training Accuracy = 59.05%\n",
            "Epoch 77: Validation Loss = 1.0302, Validation Accuracy = 54.81%\n",
            "Epoch 78: Training Loss = 0.3186, Training Accuracy = 59.29%\n",
            "Epoch 78: Validation Loss = 0.9504, Validation Accuracy = 59.50%\n",
            "Epoch 79: Training Loss = 0.2907, Training Accuracy = 60.62%\n",
            "Epoch 79: Validation Loss = 1.0250, Validation Accuracy = 56.53%\n",
            "Epoch 80: Training Loss = 0.2773, Training Accuracy = 61.77%\n",
            "Epoch 80: Validation Loss = 1.0429, Validation Accuracy = 55.88%\n",
            "Epoch 81: Training Loss = 0.2741, Training Accuracy = 62.23%\n",
            "Epoch 81: Validation Loss = 1.0727, Validation Accuracy = 54.45%\n",
            "Epoch 82: Training Loss = 0.2802, Training Accuracy = 62.18%\n",
            "Epoch 82: Validation Loss = 1.1258, Validation Accuracy = 53.74%\n",
            "Epoch 83: Training Loss = 0.2923, Training Accuracy = 61.82%\n",
            "Epoch 83: Validation Loss = 1.0919, Validation Accuracy = 56.41%\n",
            "Epoch 84: Training Loss = 0.2932, Training Accuracy = 61.77%\n",
            "Epoch 84: Validation Loss = 1.0966, Validation Accuracy = 54.69%\n",
            "Epoch 85: Training Loss = 0.2796, Training Accuracy = 62.30%\n",
            "Epoch 85: Validation Loss = 1.0241, Validation Accuracy = 56.77%\n",
            "Epoch 86: Training Loss = 0.2622, Training Accuracy = 63.06%\n",
            "Epoch 86: Validation Loss = 1.0406, Validation Accuracy = 58.02%\n",
            "Epoch 87: Training Loss = 0.2766, Training Accuracy = 62.95%\n",
            "Epoch 87: Validation Loss = 0.9423, Validation Accuracy = 57.78%\n",
            "Epoch 88: Training Loss = 0.2851, Training Accuracy = 62.46%\n",
            "Epoch 88: Validation Loss = 0.9902, Validation Accuracy = 57.42%\n",
            "Epoch 89: Training Loss = 0.2741, Training Accuracy = 63.21%\n",
            "Epoch 89: Validation Loss = 0.9559, Validation Accuracy = 60.57%\n",
            "Epoch 90: Training Loss = 0.2461, Training Accuracy = 65.39%\n",
            "Epoch 90: Validation Loss = 1.0546, Validation Accuracy = 57.78%\n",
            "Epoch 91: Training Loss = 0.2396, Training Accuracy = 65.69%\n",
            "Epoch 91: Validation Loss = 0.9823, Validation Accuracy = 60.27%\n",
            "Epoch 92: Training Loss = 0.2630, Training Accuracy = 64.71%\n",
            "Epoch 92: Validation Loss = 1.1211, Validation Accuracy = 57.24%\n",
            "Epoch 93: Training Loss = 0.2661, Training Accuracy = 64.44%\n",
            "Epoch 93: Validation Loss = 0.9757, Validation Accuracy = 60.04%\n",
            "Epoch 94: Training Loss = 0.2651, Training Accuracy = 64.41%\n",
            "Epoch 94: Validation Loss = 1.0159, Validation Accuracy = 59.74%\n",
            "Epoch 95: Training Loss = 0.2482, Training Accuracy = 65.54%\n",
            "Epoch 95: Validation Loss = 1.0636, Validation Accuracy = 57.96%\n",
            "Epoch 96: Training Loss = 0.2339, Training Accuracy = 67.22%\n",
            "Epoch 96: Validation Loss = 0.9998, Validation Accuracy = 58.91%\n",
            "Epoch 97: Training Loss = 0.2678, Training Accuracy = 64.13%\n",
            "Epoch 97: Validation Loss = 0.9655, Validation Accuracy = 60.87%\n",
            "Epoch 98: Training Loss = 0.2870, Training Accuracy = 64.12%\n",
            "Epoch 98: Validation Loss = 1.0349, Validation Accuracy = 58.43%\n",
            "Epoch 99: Training Loss = 0.2738, Training Accuracy = 64.71%\n",
            "Epoch 99: Validation Loss = 0.9844, Validation Accuracy = 59.09%\n",
            "Epoch 100: Training Loss = 0.2478, Training Accuracy = 66.27%\n",
            "Epoch 100: Validation Loss = 1.0461, Validation Accuracy = 57.78%\n",
            "Epoch 101: Training Loss = 0.2459, Training Accuracy = 66.69%\n",
            "Epoch 101: Validation Loss = 1.0340, Validation Accuracy = 58.37%\n",
            "Epoch 102: Training Loss = 0.2287, Training Accuracy = 67.88%\n",
            "Epoch 102: Validation Loss = 1.0285, Validation Accuracy = 58.37%\n",
            "Epoch 103: Training Loss = 0.2383, Training Accuracy = 67.94%\n",
            "Epoch 103: Validation Loss = 1.2371, Validation Accuracy = 52.85%\n",
            "Epoch 104: Training Loss = 0.2503, Training Accuracy = 65.65%\n",
            "Epoch 104: Validation Loss = 1.0364, Validation Accuracy = 59.14%\n",
            "Epoch 105: Training Loss = 0.2279, Training Accuracy = 68.01%\n",
            "Epoch 105: Validation Loss = 1.0754, Validation Accuracy = 58.02%\n",
            "Epoch 106: Training Loss = 0.2239, Training Accuracy = 68.27%\n",
            "Epoch 106: Validation Loss = 0.9880, Validation Accuracy = 60.21%\n",
            "Epoch 107: Training Loss = 0.2161, Training Accuracy = 69.46%\n",
            "Epoch 107: Validation Loss = 1.0296, Validation Accuracy = 58.55%\n",
            "Epoch 108: Training Loss = 0.2550, Training Accuracy = 68.09%\n",
            "Epoch 108: Validation Loss = 1.1991, Validation Accuracy = 56.29%\n",
            "Epoch 109: Training Loss = 0.2605, Training Accuracy = 65.94%\n",
            "Epoch 109: Validation Loss = 1.0040, Validation Accuracy = 59.26%\n",
            "Epoch 110: Training Loss = 0.2203, Training Accuracy = 69.17%\n",
            "Epoch 110: Validation Loss = 0.9978, Validation Accuracy = 59.50%\n",
            "Epoch 111: Training Loss = 0.2155, Training Accuracy = 70.12%\n",
            "Epoch 111: Validation Loss = 1.0952, Validation Accuracy = 60.21%\n",
            "Epoch 112: Training Loss = 0.2291, Training Accuracy = 68.67%\n",
            "Epoch 112: Validation Loss = 1.0766, Validation Accuracy = 58.02%\n",
            "Epoch 113: Training Loss = 0.2278, Training Accuracy = 69.15%\n",
            "Epoch 113: Validation Loss = 1.0374, Validation Accuracy = 60.75%\n",
            "Epoch 114: Training Loss = 0.2135, Training Accuracy = 70.51%\n",
            "Epoch 114: Validation Loss = 1.1017, Validation Accuracy = 60.10%\n",
            "Epoch 115: Training Loss = 0.2220, Training Accuracy = 70.21%\n",
            "Epoch 115: Validation Loss = 1.0833, Validation Accuracy = 58.37%\n",
            "Epoch 116: Training Loss = 0.2435, Training Accuracy = 68.45%\n",
            "Epoch 116: Validation Loss = 1.0184, Validation Accuracy = 58.97%\n",
            "Epoch 117: Training Loss = 0.2051, Training Accuracy = 71.09%\n",
            "Epoch 117: Validation Loss = 1.1060, Validation Accuracy = 58.55%\n",
            "Epoch 118: Training Loss = 0.1936, Training Accuracy = 72.27%\n",
            "Epoch 118: Validation Loss = 1.0084, Validation Accuracy = 60.69%\n",
            "Epoch 119: Training Loss = 0.1862, Training Accuracy = 73.66%\n",
            "Epoch 119: Validation Loss = 0.9777, Validation Accuracy = 62.65%\n",
            "Epoch 120: Training Loss = 0.2211, Training Accuracy = 70.43%\n",
            "Epoch 120: Validation Loss = 0.9489, Validation Accuracy = 62.59%\n",
            "Epoch 121: Training Loss = 0.2118, Training Accuracy = 70.95%\n",
            "Epoch 121: Validation Loss = 1.0321, Validation Accuracy = 60.93%\n",
            "Epoch 122: Training Loss = 0.1920, Training Accuracy = 72.88%\n",
            "Epoch 122: Validation Loss = 1.0335, Validation Accuracy = 61.16%\n",
            "Epoch 123: Training Loss = 0.1870, Training Accuracy = 73.28%\n",
            "Epoch 123: Validation Loss = 1.0637, Validation Accuracy = 61.05%\n",
            "Epoch 124: Training Loss = 0.2038, Training Accuracy = 71.46%\n",
            "Epoch 124: Validation Loss = 1.0680, Validation Accuracy = 61.22%\n",
            "Epoch 125: Training Loss = 0.1968, Training Accuracy = 72.40%\n",
            "Epoch 125: Validation Loss = 1.1064, Validation Accuracy = 59.68%\n",
            "Epoch 126: Training Loss = 0.2258, Training Accuracy = 70.91%\n",
            "Epoch 126: Validation Loss = 1.1477, Validation Accuracy = 59.38%\n",
            "Epoch 127: Training Loss = 0.1938, Training Accuracy = 72.65%\n",
            "Epoch 127: Validation Loss = 1.1108, Validation Accuracy = 60.69%\n",
            "Epoch 128: Training Loss = 0.1847, Training Accuracy = 73.83%\n",
            "Epoch 128: Validation Loss = 1.2718, Validation Accuracy = 57.01%\n",
            "Epoch 129: Training Loss = 0.1955, Training Accuracy = 72.47%\n",
            "Epoch 129: Validation Loss = 1.0671, Validation Accuracy = 59.20%\n",
            "Epoch 130: Training Loss = 0.1802, Training Accuracy = 74.17%\n",
            "Epoch 130: Validation Loss = 1.1412, Validation Accuracy = 60.21%\n",
            "Epoch 131: Training Loss = 0.1730, Training Accuracy = 74.89%\n",
            "Epoch 131: Validation Loss = 1.0873, Validation Accuracy = 61.58%\n",
            "Epoch 132: Training Loss = 0.1552, Training Accuracy = 77.34%\n",
            "Epoch 132: Validation Loss = 1.1776, Validation Accuracy = 61.52%\n",
            "Epoch 133: Training Loss = 0.1546, Training Accuracy = 76.96%\n",
            "Epoch 133: Validation Loss = 1.1497, Validation Accuracy = 61.76%\n",
            "Epoch 134: Training Loss = 0.1529, Training Accuracy = 77.52%\n",
            "Epoch 134: Validation Loss = 1.1402, Validation Accuracy = 60.21%\n",
            "Epoch 135: Training Loss = 0.2038, Training Accuracy = 73.41%\n",
            "Epoch 135: Validation Loss = 1.1801, Validation Accuracy = 59.38%\n",
            "Epoch 136: Training Loss = 0.1915, Training Accuracy = 73.32%\n",
            "Epoch 136: Validation Loss = 1.0073, Validation Accuracy = 62.71%\n",
            "Epoch 137: Training Loss = 0.1781, Training Accuracy = 76.10%\n",
            "Epoch 137: Validation Loss = 1.0839, Validation Accuracy = 62.35%\n",
            "Epoch 138: Training Loss = 0.1721, Training Accuracy = 75.65%\n",
            "Epoch 138: Validation Loss = 1.1374, Validation Accuracy = 60.93%\n",
            "Epoch 139: Training Loss = 0.1778, Training Accuracy = 74.48%\n",
            "Epoch 139: Validation Loss = 1.0815, Validation Accuracy = 61.40%\n",
            "Epoch 140: Training Loss = 0.2000, Training Accuracy = 72.99%\n",
            "Epoch 140: Validation Loss = 1.0966, Validation Accuracy = 61.58%\n",
            "Epoch 141: Training Loss = 0.1890, Training Accuracy = 72.97%\n",
            "Epoch 141: Validation Loss = 1.0750, Validation Accuracy = 63.12%\n",
            "Epoch 142: Training Loss = 0.1686, Training Accuracy = 75.68%\n",
            "Epoch 142: Validation Loss = 1.1385, Validation Accuracy = 60.33%\n",
            "Epoch 143: Training Loss = 0.1690, Training Accuracy = 75.55%\n",
            "Epoch 143: Validation Loss = 1.1697, Validation Accuracy = 61.22%\n",
            "Epoch 144: Training Loss = 0.1509, Training Accuracy = 78.00%\n",
            "Epoch 144: Validation Loss = 1.1242, Validation Accuracy = 62.47%\n",
            "Epoch 145: Training Loss = 0.1838, Training Accuracy = 75.44%\n",
            "Epoch 145: Validation Loss = 1.0680, Validation Accuracy = 63.00%\n",
            "Epoch 146: Training Loss = 0.2019, Training Accuracy = 74.93%\n",
            "Epoch 146: Validation Loss = 1.2063, Validation Accuracy = 59.20%\n",
            "Epoch 147: Training Loss = 0.1819, Training Accuracy = 75.10%\n",
            "Epoch 147: Validation Loss = 1.1855, Validation Accuracy = 60.69%\n",
            "Epoch 148: Training Loss = 0.1611, Training Accuracy = 76.97%\n",
            "Epoch 148: Validation Loss = 0.9798, Validation Accuracy = 63.30%\n",
            "Epoch 149: Training Loss = 0.1394, Training Accuracy = 79.65%\n",
            "Epoch 149: Validation Loss = 1.1432, Validation Accuracy = 62.59%\n",
            "Epoch 150: Training Loss = 0.1735, Training Accuracy = 77.66%\n",
            "Epoch 150: Validation Loss = 1.2434, Validation Accuracy = 61.05%\n",
            "Evaluating on test set:\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.50      0.63      1065\n",
            "           1       0.25      0.82      0.39        96\n",
            "           2       0.62      0.74      0.68       105\n",
            "           3       0.52      0.66      0.58       103\n",
            "           4       0.48      0.93      0.64        95\n",
            "           5       0.59      0.76      0.66       111\n",
            "           6       0.55      0.81      0.66       106\n",
            "           7       0.18      0.75      0.29         4\n",
            "\n",
            "    accuracy                           0.61      1685\n",
            "   macro avg       0.51      0.75      0.57      1685\n",
            "weighted avg       0.73      0.61      0.62      1685\n",
            "\n",
            "Confusion Matrix:\n",
            "[[535 233  45  60  81  56  49   6]\n",
            " [ 17  79   0   0   0   0   0   0]\n",
            " [ 24   0  78   0   0   0   3   0]\n",
            " [ 16   0   1  68   0   0  17   1]\n",
            " [  5   0   0   0  88   2   0   0]\n",
            " [ 13   0   0   0  12  84   0   2]\n",
            " [ 11   0   1   2   1   0  86   5]\n",
            " [  0   0   0   0   0   0   1   3]]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from emg_dataset import *  # Make sure this import is correct\n",
        "\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden and cell states with zeros\n",
        "        h0 = torch.zeros(self.lstm.num_layers, x.size(0), self.lstm.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.lstm.num_layers, x.size(0), self.lstm.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        return self.fc(out[:, -1, :])  # Only take the output from the last sequence step\n",
        "\n",
        "def compute_class_weights(dataset):\n",
        "    # Extract labels from the dataset\n",
        "    labels = [label for _, label in dataset]\n",
        "    labels = torch.tensor(labels)\n",
        "    class_counts = labels.bincount()\n",
        "    total_samples = len(labels)\n",
        "    class_weights = total_samples / (class_counts * len(class_counts))\n",
        "    return class_weights\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for sequences, labels in train_loader:\n",
        "            sequences, labels = sequences.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(sequences)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = total_loss / len(train_loader)\n",
        "        train_accuracy = 100 * correct / total\n",
        "        print(f'Epoch {epoch + 1}: Training Loss = {train_loss:.4f}, Training Accuracy = {train_accuracy:.2f}%')\n",
        "\n",
        "        val_loss, val_accuracy = evaluate_model(model, val_loader, device, is_testing=False)\n",
        "        print(f'Epoch {epoch + 1}: Validation Loss = {val_loss:.4f}, Validation Accuracy = {val_accuracy:.2f}%')\n",
        "\n",
        "def evaluate_model(model, loader, device, is_testing=False):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for sequences, labels in loader:\n",
        "            sequences, labels = sequences.to(device), labels.to(device)\n",
        "            outputs = model(sequences)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            if is_testing:\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    average_loss = total_loss / len(loader)\n",
        "    accuracy = 100 * correct / total\n",
        "\n",
        "    if is_testing:\n",
        "        print(\"Classification Report:\")\n",
        "        print(classification_report(all_labels, all_predictions))\n",
        "        print(\"Confusion Matrix:\")\n",
        "        print(confusion_matrix(all_labels, all_predictions))\n",
        "\n",
        "    return average_loss, accuracy\n",
        "\n",
        "\n",
        "def main():\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.set_device(4)  # Adjust the device index as necessary\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    dataset = EMGDataset('./EMG_Data/')\n",
        "    total_count = len(dataset)\n",
        "    train_count = int(0.8 * total_count)\n",
        "    val_count = int(0.1 * total_count)\n",
        "    test_count = total_count - train_count - val_count\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_count, val_count, test_count])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    model = LSTMClassifier(input_dim=8, hidden_dim=64, output_dim=8, num_layers=2)\n",
        "    model.to(device)\n",
        "\n",
        "    class_weights = compute_class_weights(train_dataset)\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    train_model(model, train_loader, val_loader, criterion, optimizer, 150, device)\n",
        "    print(\"Evaluating on test set:\")\n",
        "    evaluate_model(model, test_loader, device, is_testing=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-29T01:14:04.175879100Z",
          "start_time": "2024-04-29T01:09:09.418083800Z"
        },
        "id": "d20e40c1c36e8863",
        "outputId": "7657e682-37d7-4d1f-88aa-4348972863cd"
      },
      "id": "d20e40c1c36e8863"
    },
    {
      "metadata": {
        "id": "beb32f3fb4d518aa"
      },
      "cell_type": "markdown",
      "source": [
        "1D CNN model"
      ],
      "id": "beb32f3fb4d518aa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Epoch 1: Train Loss = 1.6745, Train Accuracy = 60.79%, Val Loss = 1.4133, Val Accuracy = 64.55%\n",
            "Epoch 2: Train Loss = 1.4286, Train Accuracy = 64.10%, Val Loss = 1.3024, Val Accuracy = 64.55%\n",
            "Epoch 3: Train Loss = 1.3859, Train Accuracy = 63.64%, Val Loss = 1.2640, Val Accuracy = 64.43%\n",
            "Epoch 4: Train Loss = 1.3582, Train Accuracy = 63.21%, Val Loss = 1.2394, Val Accuracy = 64.43%\n",
            "Epoch 5: Train Loss = 1.3364, Train Accuracy = 63.00%, Val Loss = 1.2155, Val Accuracy = 64.49%\n",
            "Epoch 6: Train Loss = 1.3202, Train Accuracy = 62.96%, Val Loss = 1.1963, Val Accuracy = 64.49%\n",
            "Epoch 7: Train Loss = 1.3068, Train Accuracy = 62.75%, Val Loss = 1.1793, Val Accuracy = 64.49%\n",
            "Epoch 8: Train Loss = 1.2868, Train Accuracy = 62.69%, Val Loss = 1.1630, Val Accuracy = 64.61%\n",
            "Epoch 9: Train Loss = 1.2715, Train Accuracy = 62.43%, Val Loss = 1.1452, Val Accuracy = 64.61%\n",
            "Epoch 10: Train Loss = 1.2607, Train Accuracy = 62.71%, Val Loss = 1.1298, Val Accuracy = 64.61%\n",
            "Epoch 11: Train Loss = 1.2400, Train Accuracy = 62.37%, Val Loss = 1.1128, Val Accuracy = 64.73%\n",
            "Epoch 12: Train Loss = 1.2380, Train Accuracy = 62.19%, Val Loss = 1.1023, Val Accuracy = 64.73%\n",
            "Epoch 13: Train Loss = 1.2262, Train Accuracy = 62.37%, Val Loss = 1.0930, Val Accuracy = 64.55%\n",
            "Epoch 14: Train Loss = 1.2206, Train Accuracy = 62.49%, Val Loss = 1.0810, Val Accuracy = 64.85%\n",
            "Epoch 15: Train Loss = 1.2102, Train Accuracy = 62.52%, Val Loss = 1.0709, Val Accuracy = 64.85%\n",
            "Epoch 16: Train Loss = 1.2045, Train Accuracy = 62.19%, Val Loss = 1.0621, Val Accuracy = 64.79%\n",
            "Epoch 17: Train Loss = 1.1954, Train Accuracy = 62.24%, Val Loss = 1.0546, Val Accuracy = 64.79%\n",
            "Epoch 18: Train Loss = 1.2006, Train Accuracy = 62.00%, Val Loss = 1.0583, Val Accuracy = 64.85%\n",
            "Epoch 19: Train Loss = 1.1924, Train Accuracy = 62.15%, Val Loss = 1.0553, Val Accuracy = 64.73%\n",
            "Epoch 20: Train Loss = 1.1858, Train Accuracy = 62.56%, Val Loss = 1.0470, Val Accuracy = 64.90%\n",
            "Epoch 21: Train Loss = 1.1812, Train Accuracy = 62.36%, Val Loss = 1.0410, Val Accuracy = 64.90%\n",
            "Epoch 22: Train Loss = 1.1832, Train Accuracy = 61.89%, Val Loss = 1.0393, Val Accuracy = 64.90%\n",
            "Epoch 23: Train Loss = 1.1691, Train Accuracy = 62.56%, Val Loss = 1.0305, Val Accuracy = 64.85%\n",
            "Epoch 24: Train Loss = 1.1758, Train Accuracy = 61.71%, Val Loss = 1.0339, Val Accuracy = 64.67%\n",
            "Epoch 25: Train Loss = 1.1715, Train Accuracy = 62.05%, Val Loss = 1.0321, Val Accuracy = 64.55%\n",
            "Epoch 26: Train Loss = 1.1719, Train Accuracy = 62.07%, Val Loss = 1.0285, Val Accuracy = 64.85%\n",
            "Epoch 27: Train Loss = 1.1683, Train Accuracy = 62.00%, Val Loss = 1.0243, Val Accuracy = 65.26%\n",
            "Epoch 28: Train Loss = 1.1675, Train Accuracy = 62.21%, Val Loss = 1.0211, Val Accuracy = 65.20%\n",
            "Epoch 29: Train Loss = 1.1704, Train Accuracy = 61.99%, Val Loss = 1.0242, Val Accuracy = 65.02%\n",
            "Epoch 30: Train Loss = 1.1661, Train Accuracy = 61.91%, Val Loss = 1.0200, Val Accuracy = 64.79%\n",
            "Epoch 31: Train Loss = 1.1635, Train Accuracy = 61.93%, Val Loss = 1.0201, Val Accuracy = 64.73%\n",
            "Epoch 32: Train Loss = 1.1547, Train Accuracy = 62.40%, Val Loss = 1.0203, Val Accuracy = 64.73%\n",
            "Epoch 33: Train Loss = 1.1549, Train Accuracy = 62.00%, Val Loss = 1.0196, Val Accuracy = 64.85%\n",
            "Epoch 34: Train Loss = 1.1607, Train Accuracy = 61.96%, Val Loss = 1.0203, Val Accuracy = 64.79%\n",
            "Epoch 35: Train Loss = 1.1547, Train Accuracy = 62.10%, Val Loss = 1.0192, Val Accuracy = 64.96%\n",
            "Epoch 36: Train Loss = 1.1592, Train Accuracy = 61.76%, Val Loss = 1.0195, Val Accuracy = 65.02%\n",
            "Epoch 37: Train Loss = 1.1559, Train Accuracy = 62.40%, Val Loss = 1.0189, Val Accuracy = 64.96%\n",
            "Epoch 38: Train Loss = 1.1605, Train Accuracy = 61.99%, Val Loss = 1.0183, Val Accuracy = 64.96%\n",
            "Epoch 39: Train Loss = 1.1517, Train Accuracy = 62.23%, Val Loss = 1.0176, Val Accuracy = 64.85%\n",
            "Epoch 40: Train Loss = 1.1677, Train Accuracy = 61.44%, Val Loss = 1.0186, Val Accuracy = 65.02%\n",
            "Epoch 41: Train Loss = 1.1557, Train Accuracy = 62.06%, Val Loss = 1.0183, Val Accuracy = 64.90%\n",
            "Epoch 42: Train Loss = 1.1495, Train Accuracy = 62.53%, Val Loss = 1.0170, Val Accuracy = 65.02%\n",
            "Epoch 43: Train Loss = 1.1575, Train Accuracy = 62.01%, Val Loss = 1.0177, Val Accuracy = 64.90%\n",
            "Epoch 44: Train Loss = 1.1555, Train Accuracy = 62.12%, Val Loss = 1.0172, Val Accuracy = 65.02%\n",
            "Epoch 45: Train Loss = 1.1528, Train Accuracy = 62.62%, Val Loss = 1.0167, Val Accuracy = 64.96%\n",
            "Epoch 46: Train Loss = 1.1510, Train Accuracy = 62.08%, Val Loss = 1.0163, Val Accuracy = 65.02%\n",
            "Epoch 47: Train Loss = 1.1558, Train Accuracy = 62.52%, Val Loss = 1.0164, Val Accuracy = 65.02%\n",
            "Epoch 48: Train Loss = 1.1532, Train Accuracy = 61.88%, Val Loss = 1.0163, Val Accuracy = 65.02%\n",
            "Epoch 49: Train Loss = 1.1537, Train Accuracy = 62.23%, Val Loss = 1.0165, Val Accuracy = 65.02%\n",
            "Epoch 50: Train Loss = 1.1560, Train Accuracy = 61.97%, Val Loss = 1.0164, Val Accuracy = 64.96%\n",
            "Epoch 51: Train Loss = 1.1556, Train Accuracy = 62.18%, Val Loss = 1.0157, Val Accuracy = 65.08%\n",
            "Epoch 52: Train Loss = 1.1584, Train Accuracy = 62.06%, Val Loss = 1.0158, Val Accuracy = 65.02%\n",
            "Epoch 53: Train Loss = 1.1576, Train Accuracy = 62.12%, Val Loss = 1.0158, Val Accuracy = 65.02%\n",
            "Epoch 54: Train Loss = 1.1476, Train Accuracy = 62.26%, Val Loss = 1.0154, Val Accuracy = 64.90%\n",
            "Epoch 55: Train Loss = 1.1505, Train Accuracy = 62.34%, Val Loss = 1.0144, Val Accuracy = 64.96%\n",
            "Epoch 56: Train Loss = 1.1555, Train Accuracy = 62.34%, Val Loss = 1.0151, Val Accuracy = 64.96%\n",
            "Epoch 57: Train Loss = 1.1563, Train Accuracy = 62.28%, Val Loss = 1.0154, Val Accuracy = 65.02%\n",
            "Epoch 58: Train Loss = 1.1590, Train Accuracy = 62.03%, Val Loss = 1.0151, Val Accuracy = 64.90%\n",
            "Epoch 59: Train Loss = 1.1543, Train Accuracy = 62.19%, Val Loss = 1.0156, Val Accuracy = 64.96%\n",
            "Epoch 60: Train Loss = 1.1551, Train Accuracy = 61.88%, Val Loss = 1.0152, Val Accuracy = 64.96%\n",
            "Epoch 61: Train Loss = 1.1507, Train Accuracy = 62.11%, Val Loss = 1.0150, Val Accuracy = 64.96%\n",
            "Epoch 62: Train Loss = 1.1533, Train Accuracy = 62.37%, Val Loss = 1.0150, Val Accuracy = 64.96%\n",
            "Epoch 63: Train Loss = 1.1596, Train Accuracy = 61.94%, Val Loss = 1.0149, Val Accuracy = 64.96%\n",
            "Epoch 64: Train Loss = 1.1561, Train Accuracy = 62.35%, Val Loss = 1.0149, Val Accuracy = 64.96%\n",
            "Epoch 65: Train Loss = 1.1565, Train Accuracy = 61.76%, Val Loss = 1.0149, Val Accuracy = 64.96%\n",
            "Epoch 66: Train Loss = 1.1605, Train Accuracy = 61.96%, Val Loss = 1.0149, Val Accuracy = 64.96%\n",
            "Epoch 67: Train Loss = 1.1521, Train Accuracy = 62.44%, Val Loss = 1.0147, Val Accuracy = 64.96%\n",
            "Epoch 68: Train Loss = 1.1484, Train Accuracy = 62.38%, Val Loss = 1.0147, Val Accuracy = 64.96%\n",
            "Epoch 69: Train Loss = 1.1547, Train Accuracy = 62.04%, Val Loss = 1.0146, Val Accuracy = 64.96%\n",
            "Epoch 70: Train Loss = 1.1437, Train Accuracy = 62.48%, Val Loss = 1.0145, Val Accuracy = 64.96%\n",
            "Epoch 71: Train Loss = 1.1544, Train Accuracy = 62.52%, Val Loss = 1.0144, Val Accuracy = 64.96%\n",
            "Epoch 72: Train Loss = 1.1521, Train Accuracy = 62.31%, Val Loss = 1.0143, Val Accuracy = 64.96%\n",
            "Epoch 73: Train Loss = 1.1540, Train Accuracy = 62.29%, Val Loss = 1.0143, Val Accuracy = 64.96%\n",
            "Epoch 74: Train Loss = 1.1440, Train Accuracy = 62.45%, Val Loss = 1.0143, Val Accuracy = 64.96%\n",
            "Epoch 75: Train Loss = 1.1509, Train Accuracy = 62.22%, Val Loss = 1.0142, Val Accuracy = 64.96%\n",
            "Epoch 76: Train Loss = 1.1545, Train Accuracy = 62.08%, Val Loss = 1.0143, Val Accuracy = 64.96%\n",
            "Epoch 77: Train Loss = 1.1575, Train Accuracy = 62.07%, Val Loss = 1.0143, Val Accuracy = 64.96%\n",
            "Epoch 78: Train Loss = 1.1556, Train Accuracy = 62.23%, Val Loss = 1.0142, Val Accuracy = 64.90%\n",
            "Epoch 79: Train Loss = 1.1505, Train Accuracy = 62.20%, Val Loss = 1.0141, Val Accuracy = 64.90%\n",
            "Epoch 80: Train Loss = 1.1570, Train Accuracy = 62.21%, Val Loss = 1.0141, Val Accuracy = 64.90%\n",
            "Epoch 81: Train Loss = 1.1463, Train Accuracy = 62.26%, Val Loss = 1.0140, Val Accuracy = 64.90%\n",
            "Epoch 82: Train Loss = 1.1546, Train Accuracy = 62.15%, Val Loss = 1.0140, Val Accuracy = 64.90%\n",
            "Epoch 83: Train Loss = 1.1567, Train Accuracy = 62.14%, Val Loss = 1.0140, Val Accuracy = 64.90%\n",
            "Epoch 84: Train Loss = 1.1481, Train Accuracy = 62.16%, Val Loss = 1.0140, Val Accuracy = 64.90%\n",
            "Epoch 85: Train Loss = 1.1532, Train Accuracy = 62.00%, Val Loss = 1.0139, Val Accuracy = 64.90%\n",
            "Epoch 86: Train Loss = 1.1447, Train Accuracy = 62.50%, Val Loss = 1.0139, Val Accuracy = 64.90%\n",
            "Epoch 87: Train Loss = 1.1555, Train Accuracy = 61.65%, Val Loss = 1.0139, Val Accuracy = 64.90%\n",
            "Epoch 88: Train Loss = 1.1514, Train Accuracy = 62.10%, Val Loss = 1.0139, Val Accuracy = 64.90%\n",
            "Epoch 89: Train Loss = 1.1521, Train Accuracy = 62.09%, Val Loss = 1.0139, Val Accuracy = 64.90%\n",
            "Epoch 90: Train Loss = 1.1562, Train Accuracy = 62.06%, Val Loss = 1.0139, Val Accuracy = 64.90%\n",
            "Epoch 91: Train Loss = 1.1479, Train Accuracy = 62.17%, Val Loss = 1.0139, Val Accuracy = 64.90%\n",
            "Epoch 92: Train Loss = 1.1546, Train Accuracy = 61.86%, Val Loss = 1.0139, Val Accuracy = 64.90%\n",
            "Epoch 93: Train Loss = 1.1549, Train Accuracy = 62.29%, Val Loss = 1.0139, Val Accuracy = 64.90%\n",
            "Epoch 94: Train Loss = 1.1538, Train Accuracy = 62.20%, Val Loss = 1.0139, Val Accuracy = 64.90%\n",
            "Epoch 95: Train Loss = 1.1564, Train Accuracy = 62.46%, Val Loss = 1.0139, Val Accuracy = 64.90%\n",
            "Epoch 96: Train Loss = 1.1522, Train Accuracy = 61.99%, Val Loss = 1.0139, Val Accuracy = 64.90%\n",
            "Epoch 97: Train Loss = 1.1573, Train Accuracy = 62.20%, Val Loss = 1.0139, Val Accuracy = 64.90%\n",
            "Epoch 98: Train Loss = 1.1549, Train Accuracy = 62.44%, Val Loss = 1.0139, Val Accuracy = 64.90%\n",
            "Epoch 99: Train Loss = 1.1587, Train Accuracy = 62.09%, Val Loss = 1.0139, Val Accuracy = 64.90%\n",
            "Epoch 100: Train Loss = 1.1550, Train Accuracy = 62.03%, Val Loss = 1.0139, Val Accuracy = 64.90%\n",
            "Evaluating on test set:\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.97      0.76      1050\n",
            "           1       0.00      0.00      0.00        96\n",
            "           2       0.59      0.11      0.19        90\n",
            "           3       0.36      0.11      0.17       112\n",
            "           4       0.20      0.01      0.02        98\n",
            "           5       0.00      0.00      0.00       102\n",
            "           6       0.00      0.00      0.00       131\n",
            "           7       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.62      1685\n",
            "   macro avg       0.22      0.15      0.14      1685\n",
            "weighted avg       0.46      0.62      0.50      1685\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1018    0    7   21    3    1    0    0]\n",
            " [  96    0    0    0    0    0    0    0]\n",
            " [  80    0   10    0    0    0    0    0]\n",
            " [ 100    0    0   12    0    0    0    0]\n",
            " [  97    0    0    0    1    0    0    0]\n",
            " [ 102    0    0    0    0    0    0    0]\n",
            " [ 130    0    0    0    1    0    0    0]\n",
            " [   6    0    0    0    0    0    0    0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/cpi12/.virtualenvs/EMG_Dataset/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/cpi12/.virtualenvs/EMG_Dataset/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/cpi12/.virtualenvs/EMG_Dataset/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from emg_dataset import EMGDataset  # Ensure this import reflects your project structure\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.optim import Adam\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "class Simple1DCNN(nn.Module):\n",
        "    def __init__(self, num_channels, num_classes):\n",
        "        super(Simple1DCNN, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.conv1 = nn.Conv1d(num_channels, 16, kernel_size=3, padding=1)\n",
        "        self.pool1 = nn.MaxPool1d(2)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
        "        self.pool2 = nn.MaxPool1d(2)\n",
        "        self.dropout2 = nn.Dropout(0.25)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = None  # To be initialized dynamically\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.float().permute(0, 2, 1)\n",
        "        x = self.dropout1(self.pool1(F.relu(self.conv1(x))))\n",
        "        x = self.dropout2(self.pool2(F.relu(self.conv2(x))))\n",
        "        x = self.flatten(x)\n",
        "        if self.fc is None:\n",
        "            self.fc = nn.Linear(x.shape[1], self.num_classes).to(self.device)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "def compute_class_weights(dataset):\n",
        "    # Assuming label tensor is already part of the dataset\n",
        "    labels = torch.tensor([label for _, label in dataset])\n",
        "    class_counts = labels.bincount()\n",
        "    total_samples = len(labels)\n",
        "    class_weights = total_samples / (class_counts * len(class_counts))\n",
        "    return class_weights.float()\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, scheduler, lambda_l1=0.01):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        # Training phase\n",
        "        for sequences, labels in train_loader:\n",
        "            sequences, labels = sequences.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(sequences)\n",
        "            loss = criterion(outputs, labels) + lambda_l1 * sum(p.abs().sum() for p in model.parameters())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Validation phase\n",
        "        val_loss, val_accuracy = evaluate_model(model, val_loader, device, is_testing=False)\n",
        "        print(f'Epoch {epoch + 1}: Train Loss = {train_loss / len(train_loader):.4f}, '\n",
        "              f'Train Accuracy = {100 * train_correct / train_total:.2f}%, '\n",
        "              f'Val Loss = {val_loss:.4f}, Val Accuracy = {val_accuracy:.2f}%')\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_model(model, loader, device, is_testing=False):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for sequences, labels in loader:\n",
        "            sequences, labels = sequences.to(device), labels.to(device)\n",
        "            outputs = model(sequences)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    if is_testing:\n",
        "        print(\"Classification Report:\")\n",
        "        print(classification_report(all_labels, all_predictions))\n",
        "        print(\"Confusion Matrix:\")\n",
        "        print(confusion_matrix(all_labels, all_predictions))\n",
        "\n",
        "    return total_loss / len(loader), 100 * correct / total\n",
        "\n",
        "\n",
        "def main():\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.set_device(5)  # Adjust the device index if necessary\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    dataset = EMGDataset('./EMG_Data')\n",
        "    total_count = len(dataset)\n",
        "    train_count = int(0.8 * total_count)\n",
        "    val_count = int(0.1 * total_count)\n",
        "    test_count = total_count - train_count - val_count\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_count, val_count, test_count])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "    num_channels = 8\n",
        "    num_classes = 8\n",
        "\n",
        "    model = Simple1DCNN(num_channels, num_classes).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr=0.001)\n",
        "    scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "\n",
        "    train_model(model, train_loader, val_loader, criterion, optimizer, 100, device, scheduler, lambda_l1=0.0001)\n",
        "    print(\"Evaluating on test set:\")\n",
        "    evaluate_model(model, test_loader, device, is_testing=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-29T01:15:15.137350500Z",
          "start_time": "2024-04-29T01:14:04.178899900Z"
        },
        "id": "90c079e8b1af9f75",
        "outputId": "53cf9e44-5ef2-40df-91d1-2f1289480de1"
      },
      "id": "90c079e8b1af9f75"
    },
    {
      "metadata": {
        "id": "7dc4435b20a0f2b3"
      },
      "cell_type": "markdown",
      "source": [
        "Vision transformer model"
      ],
      "id": "7dc4435b20a0f2b3"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-29T06:25:20.461591800Z",
          "start_time": "2024-04-29T05:44:43.056257600Z"
        },
        "id": "22e5cc50eef55072",
        "outputId": "8eaab49c-913c-46d2-b5f7-9b030b852fd4"
      },
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda:1\n",
            "Unique labels in the dataset: [0 1 2 3 4 5 6 7]\n",
            "Epoch 1: Training Loss = 2.1621, Training Accuracy = 14.83%\n",
            "Epoch 1: Validation Loss = 2.0138, Validation Accuracy = 6.06%\n",
            "Epoch 2: Training Loss = 2.0897, Training Accuracy = 18.31%\n",
            "Epoch 2: Validation Loss = 1.8133, Validation Accuracy = 5.88%\n",
            "Epoch 3: Training Loss = 2.0692, Training Accuracy = 22.20%\n",
            "Epoch 3: Validation Loss = 1.7987, Validation Accuracy = 63.84%\n",
            "Epoch 4: Training Loss = 2.0739, Training Accuracy = 20.71%\n",
            "Epoch 4: Validation Loss = 1.8488, Validation Accuracy = 5.88%\n",
            "Epoch 5: Training Loss = 2.0610, Training Accuracy = 20.10%\n",
            "Epoch 5: Validation Loss = 1.9400, Validation Accuracy = 5.88%\n",
            "Epoch 6: Training Loss = 2.0592, Training Accuracy = 23.32%\n",
            "Epoch 6: Validation Loss = 1.9295, Validation Accuracy = 6.29%\n",
            "Epoch 7: Training Loss = 2.0538, Training Accuracy = 21.92%\n",
            "Epoch 7: Validation Loss = 1.9321, Validation Accuracy = 6.29%\n",
            "Epoch 8: Training Loss = 2.0559, Training Accuracy = 21.70%\n",
            "Epoch 8: Validation Loss = 1.9712, Validation Accuracy = 6.29%\n",
            "Epoch 9: Training Loss = 2.0554, Training Accuracy = 22.01%\n",
            "Epoch 9: Validation Loss = 1.9095, Validation Accuracy = 5.88%\n",
            "Epoch 10: Training Loss = 2.0502, Training Accuracy = 27.54%\n",
            "Epoch 10: Validation Loss = 1.9139, Validation Accuracy = 5.88%\n",
            "Epoch 11: Training Loss = 2.0530, Training Accuracy = 28.59%\n",
            "Epoch 11: Validation Loss = 1.8661, Validation Accuracy = 63.84%\n",
            "Epoch 12: Training Loss = 2.0510, Training Accuracy = 30.63%\n",
            "Epoch 12: Validation Loss = 1.9130, Validation Accuracy = 5.88%\n",
            "Epoch 13: Training Loss = 2.0484, Training Accuracy = 32.00%\n",
            "Epoch 13: Validation Loss = 2.0090, Validation Accuracy = 5.88%\n",
            "Epoch 14: Training Loss = 2.0499, Training Accuracy = 26.83%\n",
            "Epoch 14: Validation Loss = 1.8692, Validation Accuracy = 6.06%\n",
            "Epoch 15: Training Loss = 2.0456, Training Accuracy = 29.40%\n",
            "Epoch 15: Validation Loss = 1.9736, Validation Accuracy = 6.29%\n",
            "Epoch 16: Training Loss = 2.0459, Training Accuracy = 28.08%\n",
            "Epoch 16: Validation Loss = 1.9743, Validation Accuracy = 5.88%\n",
            "Epoch 17: Training Loss = 2.0449, Training Accuracy = 27.58%\n",
            "Epoch 17: Validation Loss = 1.9239, Validation Accuracy = 63.84%\n",
            "Epoch 18: Training Loss = 2.0455, Training Accuracy = 30.09%\n",
            "Epoch 18: Validation Loss = 1.8646, Validation Accuracy = 63.84%\n",
            "Epoch 19: Training Loss = 2.0441, Training Accuracy = 37.78%\n",
            "Epoch 19: Validation Loss = 1.8903, Validation Accuracy = 63.84%\n",
            "Epoch 20: Training Loss = 2.0412, Training Accuracy = 32.48%\n",
            "Epoch 20: Validation Loss = 1.9450, Validation Accuracy = 63.84%\n",
            "Epoch 21: Training Loss = 2.0424, Training Accuracy = 34.89%\n",
            "Epoch 21: Validation Loss = 1.8689, Validation Accuracy = 63.84%\n",
            "Epoch 22: Training Loss = 2.0441, Training Accuracy = 34.70%\n",
            "Epoch 22: Validation Loss = 1.9547, Validation Accuracy = 5.58%\n",
            "Epoch 23: Training Loss = 2.0445, Training Accuracy = 36.90%\n",
            "Epoch 23: Validation Loss = 1.9386, Validation Accuracy = 63.84%\n",
            "Epoch 24: Training Loss = 2.0415, Training Accuracy = 40.70%\n",
            "Epoch 24: Validation Loss = 1.9660, Validation Accuracy = 5.88%\n",
            "Epoch 25: Training Loss = 2.0412, Training Accuracy = 41.20%\n",
            "Epoch 25: Validation Loss = 2.0292, Validation Accuracy = 6.29%\n",
            "Epoch 26: Training Loss = 2.0428, Training Accuracy = 32.07%\n",
            "Epoch 26: Validation Loss = 1.8563, Validation Accuracy = 63.84%\n",
            "Epoch 27: Training Loss = 2.0413, Training Accuracy = 40.25%\n",
            "Epoch 27: Validation Loss = 1.9391, Validation Accuracy = 6.06%\n",
            "Epoch 28: Training Loss = 2.0415, Training Accuracy = 35.11%\n",
            "Epoch 28: Validation Loss = 1.8528, Validation Accuracy = 63.84%\n",
            "Epoch 29: Training Loss = 2.0398, Training Accuracy = 42.29%\n",
            "Epoch 29: Validation Loss = 1.9746, Validation Accuracy = 6.29%\n",
            "Epoch 30: Training Loss = 2.0402, Training Accuracy = 37.15%\n",
            "Epoch 30: Validation Loss = 1.9056, Validation Accuracy = 63.84%\n",
            "Epoch 31: Training Loss = 2.0412, Training Accuracy = 43.53%\n",
            "Epoch 31: Validation Loss = 1.9348, Validation Accuracy = 6.18%\n",
            "Epoch 32: Training Loss = 2.0387, Training Accuracy = 40.27%\n",
            "Epoch 32: Validation Loss = 1.9348, Validation Accuracy = 5.58%\n",
            "Epoch 33: Training Loss = 2.0391, Training Accuracy = 40.07%\n",
            "Epoch 33: Validation Loss = 1.8519, Validation Accuracy = 63.84%\n",
            "Epoch 34: Training Loss = 2.0393, Training Accuracy = 46.67%\n",
            "Epoch 34: Validation Loss = 1.9939, Validation Accuracy = 5.88%\n",
            "Epoch 35: Training Loss = 2.0415, Training Accuracy = 36.87%\n",
            "Epoch 35: Validation Loss = 1.9078, Validation Accuracy = 63.84%\n",
            "Epoch 36: Training Loss = 2.0392, Training Accuracy = 45.68%\n",
            "Epoch 36: Validation Loss = 1.9674, Validation Accuracy = 6.29%\n",
            "Epoch 37: Training Loss = 2.0371, Training Accuracy = 37.43%\n",
            "Epoch 37: Validation Loss = 1.9930, Validation Accuracy = 5.88%\n",
            "Epoch 38: Training Loss = 2.0370, Training Accuracy = 43.57%\n",
            "Epoch 38: Validation Loss = 1.9295, Validation Accuracy = 63.84%\n",
            "Epoch 39: Training Loss = 2.0393, Training Accuracy = 41.67%\n",
            "Epoch 39: Validation Loss = 1.8730, Validation Accuracy = 63.84%\n",
            "Epoch 40: Training Loss = 2.0396, Training Accuracy = 49.57%\n",
            "Epoch 40: Validation Loss = 1.9353, Validation Accuracy = 63.84%\n",
            "Epoch 41: Training Loss = 2.0352, Training Accuracy = 51.75%\n",
            "Epoch 41: Validation Loss = 1.9349, Validation Accuracy = 63.84%\n",
            "Epoch 42: Training Loss = 2.0369, Training Accuracy = 47.60%\n",
            "Epoch 42: Validation Loss = 1.9245, Validation Accuracy = 63.84%\n",
            "Epoch 43: Training Loss = 2.0387, Training Accuracy = 50.80%\n",
            "Epoch 43: Validation Loss = 1.9064, Validation Accuracy = 63.84%\n",
            "Epoch 44: Training Loss = 2.0380, Training Accuracy = 49.68%\n",
            "Epoch 44: Validation Loss = 1.9119, Validation Accuracy = 5.58%\n",
            "Epoch 45: Training Loss = 2.0382, Training Accuracy = 50.51%\n",
            "Epoch 45: Validation Loss = 1.8737, Validation Accuracy = 63.84%\n",
            "Epoch 46: Training Loss = 2.0386, Training Accuracy = 49.45%\n",
            "Epoch 46: Validation Loss = 1.8675, Validation Accuracy = 63.84%\n",
            "Epoch 47: Training Loss = 2.0368, Training Accuracy = 48.07%\n",
            "Epoch 47: Validation Loss = 1.8872, Validation Accuracy = 63.84%\n",
            "Epoch 48: Training Loss = 2.0384, Training Accuracy = 47.96%\n",
            "Epoch 48: Validation Loss = 1.8571, Validation Accuracy = 63.84%\n",
            "Epoch 49: Training Loss = 2.0392, Training Accuracy = 52.08%\n",
            "Epoch 49: Validation Loss = 1.9488, Validation Accuracy = 6.29%\n",
            "Epoch 50: Training Loss = 2.0381, Training Accuracy = 48.33%\n",
            "Epoch 50: Validation Loss = 1.9220, Validation Accuracy = 63.84%\n",
            "Epoch 51: Training Loss = 2.0362, Training Accuracy = 47.06%\n",
            "Epoch 51: Validation Loss = 1.9258, Validation Accuracy = 5.88%\n",
            "Epoch 52: Training Loss = 2.0377, Training Accuracy = 56.20%\n",
            "Epoch 52: Validation Loss = 1.9455, Validation Accuracy = 63.84%\n",
            "Epoch 53: Training Loss = 2.0369, Training Accuracy = 52.33%\n",
            "Epoch 53: Validation Loss = 1.9399, Validation Accuracy = 5.88%\n",
            "Epoch 54: Training Loss = 2.0379, Training Accuracy = 54.43%\n",
            "Epoch 54: Validation Loss = 1.9785, Validation Accuracy = 5.88%\n",
            "Epoch 55: Training Loss = 2.0357, Training Accuracy = 54.69%\n",
            "Epoch 55: Validation Loss = 1.9410, Validation Accuracy = 6.29%\n",
            "Epoch 56: Training Loss = 2.0379, Training Accuracy = 52.18%\n",
            "Epoch 56: Validation Loss = 1.8923, Validation Accuracy = 63.84%\n",
            "Epoch 57: Training Loss = 2.0392, Training Accuracy = 56.51%\n",
            "Epoch 57: Validation Loss = 1.9255, Validation Accuracy = 63.84%\n",
            "Epoch 58: Training Loss = 2.0341, Training Accuracy = 61.17%\n",
            "Epoch 58: Validation Loss = 1.8701, Validation Accuracy = 63.84%\n",
            "Epoch 59: Training Loss = 2.0367, Training Accuracy = 57.06%\n",
            "Epoch 59: Validation Loss = 1.9390, Validation Accuracy = 63.84%\n",
            "Epoch 60: Training Loss = 2.0371, Training Accuracy = 61.77%\n",
            "Epoch 60: Validation Loss = 1.8992, Validation Accuracy = 63.84%\n",
            "Epoch 61: Training Loss = 2.0369, Training Accuracy = 55.53%\n",
            "Epoch 61: Validation Loss = 1.9158, Validation Accuracy = 63.84%\n",
            "Epoch 62: Training Loss = 2.0362, Training Accuracy = 52.71%\n",
            "Epoch 62: Validation Loss = 1.8907, Validation Accuracy = 63.84%\n",
            "Epoch 63: Training Loss = 2.0364, Training Accuracy = 57.54%\n",
            "Epoch 63: Validation Loss = 1.9043, Validation Accuracy = 63.84%\n",
            "Epoch 64: Training Loss = 2.0357, Training Accuracy = 57.91%\n",
            "Epoch 64: Validation Loss = 1.9216, Validation Accuracy = 63.84%\n",
            "Epoch 65: Training Loss = 2.0347, Training Accuracy = 53.10%\n",
            "Epoch 65: Validation Loss = 1.9102, Validation Accuracy = 63.84%\n",
            "Epoch 66: Training Loss = 2.0372, Training Accuracy = 55.00%\n",
            "Epoch 66: Validation Loss = 1.9592, Validation Accuracy = 5.88%\n",
            "Epoch 67: Training Loss = 2.0356, Training Accuracy = 58.43%\n",
            "Epoch 67: Validation Loss = 1.8923, Validation Accuracy = 63.84%\n",
            "Epoch 68: Training Loss = 2.0383, Training Accuracy = 58.13%\n",
            "Epoch 68: Validation Loss = 1.9327, Validation Accuracy = 5.88%\n",
            "Epoch 69: Training Loss = 2.0375, Training Accuracy = 48.73%\n",
            "Epoch 69: Validation Loss = 1.9000, Validation Accuracy = 63.84%\n",
            "Epoch 70: Training Loss = 2.0352, Training Accuracy = 59.70%\n",
            "Epoch 70: Validation Loss = 1.9214, Validation Accuracy = 63.84%\n",
            "Epoch 71: Training Loss = 2.0337, Training Accuracy = 59.64%\n",
            "Epoch 71: Validation Loss = 1.8882, Validation Accuracy = 63.84%\n",
            "Epoch 72: Training Loss = 2.0375, Training Accuracy = 57.15%\n",
            "Epoch 72: Validation Loss = 1.9342, Validation Accuracy = 63.84%\n",
            "Epoch 73: Training Loss = 2.0377, Training Accuracy = 63.21%\n",
            "Epoch 73: Validation Loss = 1.8722, Validation Accuracy = 63.84%\n",
            "Epoch 74: Training Loss = 2.0366, Training Accuracy = 60.08%\n",
            "Epoch 74: Validation Loss = 1.9222, Validation Accuracy = 63.84%\n",
            "Epoch 75: Training Loss = 2.0365, Training Accuracy = 57.02%\n",
            "Epoch 75: Validation Loss = 1.9134, Validation Accuracy = 63.84%\n",
            "Epoch 76: Training Loss = 2.0353, Training Accuracy = 58.06%\n",
            "Epoch 76: Validation Loss = 1.8627, Validation Accuracy = 63.84%\n",
            "Epoch 77: Training Loss = 2.0357, Training Accuracy = 53.20%\n",
            "Epoch 77: Validation Loss = 1.9872, Validation Accuracy = 6.29%\n",
            "Epoch 78: Training Loss = 2.0354, Training Accuracy = 63.36%\n",
            "Epoch 78: Validation Loss = 1.9163, Validation Accuracy = 63.84%\n",
            "Epoch 79: Training Loss = 2.0362, Training Accuracy = 59.81%\n",
            "Epoch 79: Validation Loss = 1.9156, Validation Accuracy = 63.84%\n",
            "Epoch 80: Training Loss = 2.0362, Training Accuracy = 57.82%\n",
            "Epoch 80: Validation Loss = 1.9175, Validation Accuracy = 63.84%\n",
            "Epoch 81: Training Loss = 2.0353, Training Accuracy = 55.87%\n",
            "Epoch 81: Validation Loss = 1.9228, Validation Accuracy = 63.84%\n",
            "Epoch 82: Training Loss = 2.0356, Training Accuracy = 59.04%\n",
            "Epoch 82: Validation Loss = 1.9225, Validation Accuracy = 63.84%\n",
            "Epoch 83: Training Loss = 2.0335, Training Accuracy = 54.41%\n",
            "Epoch 83: Validation Loss = 1.9207, Validation Accuracy = 6.06%\n",
            "Epoch 84: Training Loss = 2.0332, Training Accuracy = 62.15%\n",
            "Epoch 84: Validation Loss = 1.9276, Validation Accuracy = 6.18%\n",
            "Epoch 85: Training Loss = 2.0368, Training Accuracy = 58.55%\n",
            "Epoch 85: Validation Loss = 1.9256, Validation Accuracy = 63.84%\n",
            "Epoch 86: Training Loss = 2.0375, Training Accuracy = 60.13%\n",
            "Epoch 86: Validation Loss = 1.9317, Validation Accuracy = 63.84%\n",
            "Epoch 87: Training Loss = 2.0360, Training Accuracy = 60.59%\n",
            "Epoch 87: Validation Loss = 1.8945, Validation Accuracy = 63.84%\n",
            "Epoch 88: Training Loss = 2.0375, Training Accuracy = 60.30%\n",
            "Epoch 88: Validation Loss = 1.9472, Validation Accuracy = 63.84%\n",
            "Epoch 89: Training Loss = 2.0356, Training Accuracy = 57.68%\n",
            "Epoch 89: Validation Loss = 1.9555, Validation Accuracy = 63.84%\n",
            "Epoch 90: Training Loss = 2.0354, Training Accuracy = 62.67%\n",
            "Epoch 90: Validation Loss = 1.8998, Validation Accuracy = 63.84%\n",
            "Epoch 91: Training Loss = 2.0355, Training Accuracy = 61.74%\n",
            "Epoch 91: Validation Loss = 1.9366, Validation Accuracy = 63.84%\n",
            "Epoch 92: Training Loss = 2.0383, Training Accuracy = 57.87%\n",
            "Epoch 92: Validation Loss = 1.9295, Validation Accuracy = 63.84%\n",
            "Epoch 93: Training Loss = 2.0356, Training Accuracy = 59.58%\n",
            "Epoch 93: Validation Loss = 1.8730, Validation Accuracy = 63.84%\n",
            "Epoch 94: Training Loss = 2.0371, Training Accuracy = 60.63%\n",
            "Epoch 94: Validation Loss = 1.9327, Validation Accuracy = 63.84%\n",
            "Epoch 95: Training Loss = 2.0362, Training Accuracy = 63.99%\n",
            "Epoch 95: Validation Loss = 1.9080, Validation Accuracy = 63.84%\n",
            "Epoch 96: Training Loss = 2.0367, Training Accuracy = 61.17%\n",
            "Epoch 96: Validation Loss = 1.9354, Validation Accuracy = 63.84%\n",
            "Epoch 97: Training Loss = 2.0359, Training Accuracy = 55.07%\n",
            "Epoch 97: Validation Loss = 1.9318, Validation Accuracy = 63.84%\n",
            "Epoch 98: Training Loss = 2.0343, Training Accuracy = 53.02%\n",
            "Epoch 98: Validation Loss = 1.9602, Validation Accuracy = 6.29%\n",
            "Epoch 99: Training Loss = 2.0371, Training Accuracy = 56.01%\n",
            "Epoch 99: Validation Loss = 1.9086, Validation Accuracy = 63.84%\n",
            "Epoch 100: Training Loss = 2.0364, Training Accuracy = 63.11%\n",
            "Epoch 100: Validation Loss = 1.9207, Validation Accuracy = 63.84%\n",
            "Epoch 101: Training Loss = 2.0373, Training Accuracy = 61.50%\n",
            "Epoch 101: Validation Loss = 1.9333, Validation Accuracy = 63.84%\n",
            "Epoch 102: Training Loss = 2.0341, Training Accuracy = 55.12%\n",
            "Epoch 102: Validation Loss = 1.9071, Validation Accuracy = 63.84%\n",
            "Epoch 103: Training Loss = 2.0370, Training Accuracy = 56.82%\n",
            "Epoch 103: Validation Loss = 1.8822, Validation Accuracy = 63.84%\n",
            "Epoch 104: Training Loss = 2.0330, Training Accuracy = 64.09%\n",
            "Epoch 104: Validation Loss = 1.9353, Validation Accuracy = 63.84%\n",
            "Epoch 105: Training Loss = 2.0368, Training Accuracy = 61.48%\n",
            "Epoch 105: Validation Loss = 1.9175, Validation Accuracy = 63.84%\n",
            "Epoch 106: Training Loss = 2.0334, Training Accuracy = 60.08%\n",
            "Epoch 106: Validation Loss = 1.9316, Validation Accuracy = 63.84%\n",
            "Epoch 107: Training Loss = 2.0371, Training Accuracy = 62.23%\n",
            "Epoch 107: Validation Loss = 1.9393, Validation Accuracy = 63.84%\n",
            "Epoch 108: Training Loss = 2.0355, Training Accuracy = 62.14%\n",
            "Epoch 108: Validation Loss = 1.9176, Validation Accuracy = 63.84%\n",
            "Epoch 109: Training Loss = 2.0343, Training Accuracy = 57.14%\n",
            "Epoch 109: Validation Loss = 1.9534, Validation Accuracy = 63.84%\n",
            "Epoch 110: Training Loss = 2.0346, Training Accuracy = 57.68%\n",
            "Epoch 110: Validation Loss = 1.9049, Validation Accuracy = 63.84%\n",
            "Epoch 111: Training Loss = 2.0332, Training Accuracy = 60.70%\n",
            "Epoch 111: Validation Loss = 1.8883, Validation Accuracy = 63.84%\n",
            "Epoch 112: Training Loss = 2.0351, Training Accuracy = 61.56%\n",
            "Epoch 112: Validation Loss = 1.9416, Validation Accuracy = 63.84%\n",
            "Epoch 113: Training Loss = 2.0357, Training Accuracy = 60.78%\n",
            "Epoch 113: Validation Loss = 1.9276, Validation Accuracy = 63.84%\n",
            "Epoch 114: Training Loss = 2.0374, Training Accuracy = 60.50%\n",
            "Epoch 114: Validation Loss = 1.9412, Validation Accuracy = 63.84%\n",
            "Epoch 115: Training Loss = 2.0364, Training Accuracy = 52.87%\n",
            "Epoch 115: Validation Loss = 1.9310, Validation Accuracy = 63.84%\n",
            "Epoch 116: Training Loss = 2.0369, Training Accuracy = 60.36%\n",
            "Epoch 116: Validation Loss = 1.9111, Validation Accuracy = 63.84%\n",
            "Epoch 117: Training Loss = 2.0347, Training Accuracy = 64.09%\n",
            "Epoch 117: Validation Loss = 1.9491, Validation Accuracy = 63.84%\n",
            "Epoch 118: Training Loss = 2.0359, Training Accuracy = 60.90%\n",
            "Epoch 118: Validation Loss = 1.9395, Validation Accuracy = 63.84%\n",
            "Epoch 119: Training Loss = 2.0362, Training Accuracy = 58.60%\n",
            "Epoch 119: Validation Loss = 1.9246, Validation Accuracy = 63.84%\n",
            "Epoch 120: Training Loss = 2.0360, Training Accuracy = 62.06%\n",
            "Epoch 120: Validation Loss = 1.9452, Validation Accuracy = 63.84%\n",
            "Epoch 121: Training Loss = 2.0362, Training Accuracy = 58.81%\n",
            "Epoch 121: Validation Loss = 1.9053, Validation Accuracy = 63.84%\n",
            "Epoch 122: Training Loss = 2.0362, Training Accuracy = 63.15%\n",
            "Epoch 122: Validation Loss = 1.9247, Validation Accuracy = 63.84%\n",
            "Epoch 123: Training Loss = 2.0337, Training Accuracy = 58.71%\n",
            "Epoch 123: Validation Loss = 1.9099, Validation Accuracy = 63.84%\n",
            "Epoch 124: Training Loss = 2.0356, Training Accuracy = 63.78%\n",
            "Epoch 124: Validation Loss = 1.8962, Validation Accuracy = 63.84%\n",
            "Epoch 125: Training Loss = 2.0371, Training Accuracy = 64.09%\n",
            "Epoch 125: Validation Loss = 1.9490, Validation Accuracy = 63.84%\n",
            "Epoch 126: Training Loss = 2.0374, Training Accuracy = 61.65%\n",
            "Epoch 126: Validation Loss = 1.9373, Validation Accuracy = 63.84%\n",
            "Epoch 127: Training Loss = 2.0341, Training Accuracy = 60.42%\n",
            "Epoch 127: Validation Loss = 1.9659, Validation Accuracy = 63.84%\n",
            "Epoch 128: Training Loss = 2.0363, Training Accuracy = 61.74%\n",
            "Epoch 128: Validation Loss = 1.8965, Validation Accuracy = 63.84%\n",
            "Epoch 129: Training Loss = 2.0368, Training Accuracy = 64.09%\n",
            "Epoch 129: Validation Loss = 1.9117, Validation Accuracy = 63.84%\n",
            "Epoch 130: Training Loss = 2.0358, Training Accuracy = 60.58%\n",
            "Epoch 130: Validation Loss = 1.9310, Validation Accuracy = 63.84%\n",
            "Epoch 131: Training Loss = 2.0351, Training Accuracy = 61.83%\n",
            "Epoch 131: Validation Loss = 1.9190, Validation Accuracy = 63.84%\n",
            "Epoch 132: Training Loss = 2.0343, Training Accuracy = 62.26%\n",
            "Epoch 132: Validation Loss = 1.9119, Validation Accuracy = 63.84%\n",
            "Epoch 133: Training Loss = 2.0376, Training Accuracy = 60.78%\n",
            "Epoch 133: Validation Loss = 1.9291, Validation Accuracy = 63.84%\n",
            "Epoch 134: Training Loss = 2.0349, Training Accuracy = 57.17%\n",
            "Epoch 134: Validation Loss = 1.9088, Validation Accuracy = 63.84%\n",
            "Epoch 135: Training Loss = 2.0365, Training Accuracy = 64.09%\n",
            "Epoch 135: Validation Loss = 1.8962, Validation Accuracy = 63.84%\n",
            "Epoch 136: Training Loss = 2.0355, Training Accuracy = 62.99%\n",
            "Epoch 136: Validation Loss = 1.9257, Validation Accuracy = 63.84%\n",
            "Epoch 137: Training Loss = 2.0341, Training Accuracy = 58.72%\n",
            "Epoch 137: Validation Loss = 1.8812, Validation Accuracy = 63.84%\n",
            "Epoch 138: Training Loss = 2.0356, Training Accuracy = 62.58%\n",
            "Epoch 138: Validation Loss = 1.9332, Validation Accuracy = 63.84%\n",
            "Epoch 139: Training Loss = 2.0340, Training Accuracy = 62.40%\n",
            "Epoch 139: Validation Loss = 1.9283, Validation Accuracy = 63.84%\n",
            "Epoch 140: Training Loss = 2.0378, Training Accuracy = 61.95%\n",
            "Epoch 140: Validation Loss = 1.9438, Validation Accuracy = 63.84%\n",
            "Epoch 141: Training Loss = 2.0356, Training Accuracy = 59.72%\n",
            "Epoch 141: Validation Loss = 1.9143, Validation Accuracy = 63.84%\n",
            "Epoch 142: Training Loss = 2.0353, Training Accuracy = 64.09%\n",
            "Epoch 142: Validation Loss = 1.9339, Validation Accuracy = 63.84%\n",
            "Epoch 143: Training Loss = 2.0372, Training Accuracy = 62.57%\n",
            "Epoch 143: Validation Loss = 1.9101, Validation Accuracy = 63.84%\n",
            "Epoch 144: Training Loss = 2.0344, Training Accuracy = 59.91%\n",
            "Epoch 144: Validation Loss = 1.9289, Validation Accuracy = 63.84%\n",
            "Epoch 145: Training Loss = 2.0374, Training Accuracy = 61.71%\n",
            "Epoch 145: Validation Loss = 1.8907, Validation Accuracy = 63.84%\n",
            "Epoch 146: Training Loss = 2.0368, Training Accuracy = 63.14%\n",
            "Epoch 146: Validation Loss = 1.9382, Validation Accuracy = 63.84%\n",
            "Epoch 147: Training Loss = 2.0346, Training Accuracy = 59.63%\n",
            "Epoch 147: Validation Loss = 1.9098, Validation Accuracy = 63.84%\n",
            "Epoch 148: Training Loss = 2.0352, Training Accuracy = 59.55%\n",
            "Epoch 148: Validation Loss = 1.9078, Validation Accuracy = 63.84%\n",
            "Epoch 149: Training Loss = 2.0355, Training Accuracy = 58.72%\n",
            "Epoch 149: Validation Loss = 1.8993, Validation Accuracy = 63.84%\n",
            "Epoch 150: Training Loss = 2.0346, Training Accuracy = 61.95%\n",
            "Epoch 150: Validation Loss = 1.9130, Validation Accuracy = 63.84%\n",
            "Evaluating on test set:\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      1.00      0.78      1073\n",
            "           1       0.00      0.00      0.00       106\n",
            "           2       0.00      0.00      0.00        97\n",
            "           3       0.00      0.00      0.00       104\n",
            "           4       0.00      0.00      0.00        93\n",
            "           5       0.00      0.00      0.00       106\n",
            "           6       0.00      0.00      0.00       103\n",
            "           7       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.64      1685\n",
            "   macro avg       0.08      0.12      0.10      1685\n",
            "weighted avg       0.41      0.64      0.50      1685\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1073    0    0    0    0    0    0    0]\n",
            " [ 106    0    0    0    0    0    0    0]\n",
            " [  97    0    0    0    0    0    0    0]\n",
            " [ 104    0    0    0    0    0    0    0]\n",
            " [  93    0    0    0    0    0    0    0]\n",
            " [ 106    0    0    0    0    0    0    0]\n",
            " [ 103    0    0    0    0    0    0    0]\n",
            " [   3    0    0    0    0    0    0    0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/cpi12/.virtualenvs/EMG_Dataset/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/cpi12/.virtualenvs/EMG_Dataset/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/cpi12/.virtualenvs/EMG_Dataset/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "execution_count": null,
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from emg_dataset import EMGDataset  # Ensure your dataset class is properly implemented\n",
        "import math\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "class PatchEmbedding(nn.Module):\n",
        "    def __init__(self, num_features, patch_size, emb_size, seq_len):\n",
        "        super(PatchEmbedding, self).__init__()\n",
        "        self.num_patches = seq_len // patch_size\n",
        "        self.patch_size = patch_size\n",
        "        self.projection = nn.Linear(num_features * patch_size, emb_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unfold(1, self.patch_size, self.patch_size)\n",
        "        x = x.contiguous().view(x.size(0), x.size(1), -1)\n",
        "        x = self.projection(x)\n",
        "        return x\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, emb_size, max_len=500):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(max_len, emb_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch_size, seq_len, emb_size)\n",
        "        # Only take as many position embeddings as needed\n",
        "        return x + self.pos_embedding[:x.size(1), :]\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, emb_size, num_heads, ff_dim, dropout=0.1):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.attention = nn.MultiheadAttention(emb_size, num_heads, dropout=dropout)\n",
        "        self.norm1 = nn.LayerNorm(emb_size)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(emb_size, ff_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(ff_dim, emb_size)\n",
        "        )\n",
        "        self.norm2 = nn.LayerNorm(emb_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attention(self.norm1(x), self.norm1(x), self.norm1(x))[0]\n",
        "        x = x + self.dropout(self.ff(self.norm2(x)))\n",
        "        return x\n",
        "\n",
        "class VisionTransformer(nn.Module):\n",
        "    def __init__(self, num_features, num_patches, patch_size, emb_size, depth, num_heads, ff_dim, num_classes, max_len=500):\n",
        "        super(VisionTransformer, self).__init__()\n",
        "        self.patch_embedding = PatchEmbedding(num_features, patch_size, emb_size, num_patches * patch_size)\n",
        "        self.pos_embedding = PositionalEncoding(emb_size, max_len)\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, emb_size))\n",
        "        self.encoders = nn.ModuleList([TransformerEncoder(emb_size, num_heads, ff_dim) for _ in range(depth)])\n",
        "        self.classifier = nn.Linear(emb_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b = x.size(0)\n",
        "        x = self.patch_embedding(x)\n",
        "        cls_tokens = self.cls_token.expand(b, -1, -1)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        x = self.pos_embedding(x)\n",
        "        for encoder in self.encoders:\n",
        "            x = encoder(x)\n",
        "        cls_token_final = x[:, 0]\n",
        "        return self.classifier(cls_token_final)\n",
        "\n",
        "\n",
        "def compute_class_weights(dataset):\n",
        "    # Assuming dataset is a PyTorch Dataset or a Subset containing (sequence, label) pairs\n",
        "    all_labels = []\n",
        "    for _, label in dataset:\n",
        "        all_labels.append(label.item())  # Assuming label is a tensor, use .item() to get its Python scalar value\n",
        "\n",
        "    all_labels = np.array(all_labels)\n",
        "    unique_labels = np.unique(all_labels)\n",
        "\n",
        "    # Compute class weights\n",
        "    class_weights = compute_class_weight(class_weight='balanced', classes=unique_labels, y=all_labels)\n",
        "\n",
        "    # Convert class weights to tensor\n",
        "    return torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for sequences, labels in train_loader:\n",
        "            sequences, labels = sequences.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(sequences)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = total_loss / len(train_loader)\n",
        "        train_accuracy = 100 * correct / total\n",
        "        print(f'Epoch {epoch + 1}: Training Loss = {train_loss:.4f}, Training Accuracy = {train_accuracy:.2f}%')\n",
        "\n",
        "        val_loss, val_accuracy = evaluate_model(model, val_loader, device, is_validation=True)\n",
        "        print(f'Epoch {epoch + 1}: Validation Loss = {val_loss:.4f}, Validation Accuracy = {val_accuracy:.2f}%')\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_model(model, loader, device, is_validation=False):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for sequences, labels in loader:\n",
        "            sequences, labels = sequences.to(device), labels.to(device)\n",
        "            outputs = model(sequences)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    average_loss = total_loss / len(loader)\n",
        "    accuracy = 100 * correct / total\n",
        "\n",
        "    if not is_validation:\n",
        "        print(\"Classification Report:\")\n",
        "        print(classification_report(all_labels, all_predictions))\n",
        "        print(\"Confusion Matrix:\")\n",
        "        print(confusion_matrix(all_labels, all_predictions))\n",
        "\n",
        "    return average_loss, accuracy\n",
        "\n",
        "def main():\n",
        "    device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    dataset = EMGDataset('./EMG_Data/')\n",
        "    total_count = len(dataset)\n",
        "    train_count = int(0.8 * total_count)\n",
        "    val_count = int(0.1 * total_count)\n",
        "    test_count = total_count - train_count - val_count\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_count, val_count, test_count])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "    model = VisionTransformer(\n",
        "        num_features=8,\n",
        "        num_patches=10,\n",
        "        patch_size=50,\n",
        "        emb_size=256,\n",
        "        depth=6,\n",
        "        num_heads=8,\n",
        "        ff_dim=512,\n",
        "        num_classes=8,\n",
        "        max_len=500\n",
        "    ).to(device)\n",
        "\n",
        "    class_weights = compute_class_weights(train_dataset)\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "    train_model(model, train_loader, val_loader, criterion, optimizer, 150, device)\n",
        "\n",
        "    print(\"Evaluating on test set:\")\n",
        "    evaluate_model(model, test_loader, device, is_validation=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "id": "22e5cc50eef55072"
    },
    {
      "metadata": {
        "id": "fb191262e25a672a"
      },
      "cell_type": "markdown",
      "source": [
        "Swin Transformer"
      ],
      "id": "fb191262e25a672a"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from emg_dataset import *\n",
        "import math\n",
        "\n",
        "# Swin Transformer Block adapted for 1D\n",
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "\n",
        "class SwinTransformerBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, window_size=7, shift_size=0):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.attn = nn.MultiheadAttention(embed_dim=dim, num_heads=num_heads)\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(dim, 2 * dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(2 * dim, dim),\n",
        "        )\n",
        "        self.window_size = window_size\n",
        "        self.shift_size = shift_size if shift_size > 0 else 0\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, L, C = x.shape\n",
        "\n",
        "        # Optional: shift the sequence for overlapping windows\n",
        "        if self.shift_size > 0:\n",
        "            x = torch.roll(x, shifts=-self.shift_size, dims=1)\n",
        "\n",
        "        # Prepare for multihead attention\n",
        "        x = x.view(B * L, 1, C)  # Reshape for multihead attention\n",
        "        x = self.norm1(x)\n",
        "        x, _ = self.attn(x, x, x)\n",
        "        x = x.view(B, L, C)  # Reshape back to original\n",
        "\n",
        "        x = self.norm2(x)\n",
        "        x = self.mlp(x) + x  # Apply MLP and add residual\n",
        "\n",
        "        return x\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:x.size(0), :]\n",
        "\n",
        "# Full model including Swin Transformer blocks\n",
        "class SwinTransformerTimeSeries(nn.Module):\n",
        "    def __init__(self, num_features, num_classes, num_heads, window_size, shift_size, depth=2):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Linear(num_features, 128)  # Embedding layer\n",
        "        self.pos_encoder = PositionalEncoding(128)\n",
        "        self.blocks = nn.ModuleList([\n",
        "            SwinTransformerBlock(128, num_heads, window_size, shift_size if i % 2 == 0 else 0)\n",
        "            for i in range(depth)\n",
        "        ])\n",
        "        self.classifier = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.pos_encoder(x)\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        x = x.mean(dim=1)  # Global average pooling\n",
        "        return self.classifier(x)\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for sequences, labels in train_loader:\n",
        "            sequences, labels = sequences.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(sequences)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = total_loss / len(train_loader)\n",
        "        train_accuracy = 100 * correct / total\n",
        "        print(f'Epoch {epoch + 1}: Training Loss = {train_loss:.4f}, Training Accuracy = {train_accuracy:.2f}%')\n",
        "\n",
        "        val_loss, val_accuracy = evaluate_model(model, val_loader, device, is_validation=True)\n",
        "        print(f'Epoch {epoch + 1}: Validation Loss = {val_loss:.4f}, Validation Accuracy = {val_accuracy:.2f}%')\n",
        "\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(model, loader, device, is_validation=False):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for sequences, labels in loader:\n",
        "            sequences, labels = sequences.to(device), labels.to(device)\n",
        "            outputs = model(sequences)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    average_loss = total_loss / len(loader)\n",
        "    accuracy = 100 * correct / total\n",
        "\n",
        "    if not is_validation:\n",
        "        print(\"Classification Report:\")\n",
        "        print(classification_report(all_labels, all_predictions))\n",
        "        print(\"Confusion Matrix:\")\n",
        "        print(confusion_matrix(all_labels, all_predictions))\n",
        "\n",
        "    return average_loss, accuracy\n",
        "\n",
        "# Main function setup and execution\n",
        "def main():\n",
        "    device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    dataset = EMGDataset('./EMG_Data/')\n",
        "    total_count = len(dataset)\n",
        "    train_count = int(0.8 * total_count)\n",
        "    val_count = int(0.1 * total_count)\n",
        "    test_count = total_count - train_count - val_count\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_count, val_count, test_count])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "    model = SwinTransformerTimeSeries(num_features=8, num_classes=8, num_heads=4, window_size=50, shift_size=25, depth=2)\n",
        "    model.apply(init_weights)  # Initialize weights\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "    train_model(model, train_loader, val_loader, criterion, optimizer, 200, device)\n",
        "    print(\"Evaluating on test set:\")\n",
        "    evaluate_model(model, test_loader, device, is_validation=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-29T05:31:35.791490300Z",
          "start_time": "2024-04-29T01:39:04.841077400Z"
        },
        "id": "e31fd4127f7d2048",
        "outputId": "eb7e1fd9-ae7a-4980-9c8c-27cf7fb71983"
      },
      "id": "e31fd4127f7d2048",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda:2\n",
            "Epoch 1: Training Loss = 1.3425, Training Accuracy = 64.06%\n",
            "Epoch 1: Validation Loss = 1.3578, Validation Accuracy = 63.78%\n",
            "Epoch 2: Training Loss = 1.3178, Training Accuracy = 64.19%\n",
            "Epoch 2: Validation Loss = 1.3457, Validation Accuracy = 63.78%\n",
            "Epoch 3: Training Loss = 1.3140, Training Accuracy = 64.19%\n",
            "Epoch 3: Validation Loss = 1.3111, Validation Accuracy = 63.78%\n",
            "Epoch 4: Training Loss = 1.2534, Training Accuracy = 63.70%\n",
            "Epoch 4: Validation Loss = 1.2231, Validation Accuracy = 63.06%\n",
            "Epoch 5: Training Loss = 1.1167, Training Accuracy = 62.82%\n",
            "Epoch 5: Validation Loss = 1.0748, Validation Accuracy = 62.23%\n",
            "Epoch 6: Training Loss = 0.9572, Training Accuracy = 63.40%\n",
            "Epoch 6: Validation Loss = 0.9187, Validation Accuracy = 64.19%\n",
            "Epoch 7: Training Loss = 0.8922, Training Accuracy = 63.76%\n",
            "Epoch 7: Validation Loss = 0.9031, Validation Accuracy = 64.07%\n",
            "Epoch 8: Training Loss = 0.8653, Training Accuracy = 64.19%\n",
            "Epoch 8: Validation Loss = 0.8308, Validation Accuracy = 65.97%\n",
            "Epoch 9: Training Loss = 0.8246, Training Accuracy = 65.46%\n",
            "Epoch 9: Validation Loss = 0.8073, Validation Accuracy = 68.53%\n",
            "Epoch 10: Training Loss = 0.7813, Training Accuracy = 66.76%\n",
            "Epoch 10: Validation Loss = 0.8037, Validation Accuracy = 67.28%\n",
            "Epoch 11: Training Loss = 0.7539, Training Accuracy = 67.81%\n",
            "Epoch 11: Validation Loss = 0.7648, Validation Accuracy = 66.75%\n",
            "Epoch 12: Training Loss = 0.7355, Training Accuracy = 68.19%\n",
            "Epoch 12: Validation Loss = 0.7440, Validation Accuracy = 68.23%\n",
            "Epoch 13: Training Loss = 0.7214, Training Accuracy = 69.03%\n",
            "Epoch 13: Validation Loss = 0.7250, Validation Accuracy = 68.65%\n",
            "Epoch 14: Training Loss = 0.7101, Training Accuracy = 69.40%\n",
            "Epoch 14: Validation Loss = 0.7205, Validation Accuracy = 69.95%\n",
            "Epoch 15: Training Loss = 0.6998, Training Accuracy = 69.75%\n",
            "Epoch 15: Validation Loss = 0.7388, Validation Accuracy = 69.00%\n",
            "Epoch 16: Training Loss = 0.7013, Training Accuracy = 69.77%\n",
            "Epoch 16: Validation Loss = 0.6995, Validation Accuracy = 70.07%\n",
            "Epoch 17: Training Loss = 0.6866, Training Accuracy = 69.99%\n",
            "Epoch 17: Validation Loss = 0.7006, Validation Accuracy = 70.07%\n",
            "Epoch 18: Training Loss = 0.6836, Training Accuracy = 70.44%\n",
            "Epoch 18: Validation Loss = 0.6955, Validation Accuracy = 69.42%\n",
            "Epoch 19: Training Loss = 0.6771, Training Accuracy = 70.77%\n",
            "Epoch 19: Validation Loss = 0.6813, Validation Accuracy = 71.38%\n",
            "Epoch 20: Training Loss = 0.6693, Training Accuracy = 71.08%\n",
            "Epoch 20: Validation Loss = 0.6839, Validation Accuracy = 71.08%\n",
            "Epoch 21: Training Loss = 0.6685, Training Accuracy = 70.71%\n",
            "Epoch 21: Validation Loss = 0.6907, Validation Accuracy = 69.89%\n",
            "Epoch 22: Training Loss = 0.6647, Training Accuracy = 71.04%\n",
            "Epoch 22: Validation Loss = 0.6905, Validation Accuracy = 69.71%\n",
            "Epoch 23: Training Loss = 0.6586, Training Accuracy = 71.13%\n",
            "Epoch 23: Validation Loss = 0.6861, Validation Accuracy = 69.95%\n",
            "Epoch 24: Training Loss = 0.6569, Training Accuracy = 71.33%\n",
            "Epoch 24: Validation Loss = 0.7067, Validation Accuracy = 68.65%\n",
            "Epoch 25: Training Loss = 0.6535, Training Accuracy = 71.72%\n",
            "Epoch 25: Validation Loss = 0.6732, Validation Accuracy = 71.79%\n",
            "Epoch 26: Training Loss = 0.6515, Training Accuracy = 71.90%\n",
            "Epoch 26: Validation Loss = 0.6739, Validation Accuracy = 71.56%\n",
            "Epoch 27: Training Loss = 0.6472, Training Accuracy = 71.96%\n",
            "Epoch 27: Validation Loss = 0.6701, Validation Accuracy = 71.79%\n",
            "Epoch 28: Training Loss = 0.6428, Training Accuracy = 72.14%\n",
            "Epoch 28: Validation Loss = 0.6874, Validation Accuracy = 71.14%\n",
            "Epoch 29: Training Loss = 0.6430, Training Accuracy = 72.30%\n",
            "Epoch 29: Validation Loss = 0.6867, Validation Accuracy = 70.49%\n",
            "Epoch 30: Training Loss = 0.6387, Training Accuracy = 71.78%\n",
            "Epoch 30: Validation Loss = 0.6654, Validation Accuracy = 71.73%\n",
            "Epoch 31: Training Loss = 0.6400, Training Accuracy = 71.74%\n",
            "Epoch 31: Validation Loss = 0.6784, Validation Accuracy = 70.72%\n",
            "Epoch 32: Training Loss = 0.6404, Training Accuracy = 72.26%\n",
            "Epoch 32: Validation Loss = 0.6708, Validation Accuracy = 71.26%\n",
            "Epoch 33: Training Loss = 0.6372, Training Accuracy = 72.82%\n",
            "Epoch 33: Validation Loss = 0.6514, Validation Accuracy = 73.34%\n",
            "Epoch 34: Training Loss = 0.6365, Training Accuracy = 72.36%\n",
            "Epoch 34: Validation Loss = 0.6553, Validation Accuracy = 71.26%\n",
            "Epoch 35: Training Loss = 0.6299, Training Accuracy = 72.64%\n",
            "Epoch 35: Validation Loss = 0.6433, Validation Accuracy = 71.67%\n",
            "Epoch 36: Training Loss = 0.6310, Training Accuracy = 72.57%\n",
            "Epoch 36: Validation Loss = 0.6519, Validation Accuracy = 71.85%\n",
            "Epoch 37: Training Loss = 0.6234, Training Accuracy = 72.78%\n",
            "Epoch 37: Validation Loss = 0.6444, Validation Accuracy = 72.68%\n",
            "Epoch 38: Training Loss = 0.6226, Training Accuracy = 72.95%\n",
            "Epoch 38: Validation Loss = 0.6475, Validation Accuracy = 70.96%\n",
            "Epoch 39: Training Loss = 0.6237, Training Accuracy = 72.78%\n",
            "Epoch 39: Validation Loss = 0.6580, Validation Accuracy = 71.02%\n",
            "Epoch 40: Training Loss = 0.6222, Training Accuracy = 72.68%\n",
            "Epoch 40: Validation Loss = 0.6465, Validation Accuracy = 73.10%\n",
            "Epoch 41: Training Loss = 0.6205, Training Accuracy = 72.92%\n",
            "Epoch 41: Validation Loss = 0.6644, Validation Accuracy = 70.61%\n",
            "Epoch 42: Training Loss = 0.6125, Training Accuracy = 73.31%\n",
            "Epoch 42: Validation Loss = 0.6309, Validation Accuracy = 72.80%\n",
            "Epoch 43: Training Loss = 0.6136, Training Accuracy = 73.34%\n",
            "Epoch 43: Validation Loss = 0.6303, Validation Accuracy = 72.62%\n",
            "Epoch 44: Training Loss = 0.6127, Training Accuracy = 73.06%\n",
            "Epoch 44: Validation Loss = 0.6329, Validation Accuracy = 73.34%\n",
            "Epoch 45: Training Loss = 0.6111, Training Accuracy = 73.37%\n",
            "Epoch 45: Validation Loss = 0.6343, Validation Accuracy = 73.34%\n",
            "Epoch 46: Training Loss = 0.6079, Training Accuracy = 73.37%\n",
            "Epoch 46: Validation Loss = 0.6252, Validation Accuracy = 74.05%\n",
            "Epoch 47: Training Loss = 0.6049, Training Accuracy = 73.46%\n",
            "Epoch 47: Validation Loss = 0.6300, Validation Accuracy = 72.03%\n",
            "Epoch 48: Training Loss = 0.6083, Training Accuracy = 73.59%\n",
            "Epoch 48: Validation Loss = 0.6292, Validation Accuracy = 73.04%\n",
            "Epoch 49: Training Loss = 0.6016, Training Accuracy = 73.82%\n",
            "Epoch 49: Validation Loss = 0.6408, Validation Accuracy = 72.98%\n",
            "Epoch 50: Training Loss = 0.5986, Training Accuracy = 73.91%\n",
            "Epoch 50: Validation Loss = 0.6332, Validation Accuracy = 74.17%\n",
            "Epoch 51: Training Loss = 0.5985, Training Accuracy = 73.69%\n",
            "Epoch 51: Validation Loss = 0.6383, Validation Accuracy = 73.16%\n",
            "Epoch 52: Training Loss = 0.5949, Training Accuracy = 73.88%\n",
            "Epoch 52: Validation Loss = 0.6381, Validation Accuracy = 72.21%\n",
            "Epoch 53: Training Loss = 0.5935, Training Accuracy = 73.98%\n",
            "Epoch 53: Validation Loss = 0.6291, Validation Accuracy = 73.22%\n",
            "Epoch 54: Training Loss = 0.5937, Training Accuracy = 73.55%\n",
            "Epoch 54: Validation Loss = 0.6142, Validation Accuracy = 73.81%\n",
            "Epoch 55: Training Loss = 0.5909, Training Accuracy = 74.15%\n",
            "Epoch 55: Validation Loss = 0.6257, Validation Accuracy = 72.62%\n",
            "Epoch 56: Training Loss = 0.5890, Training Accuracy = 74.02%\n",
            "Epoch 56: Validation Loss = 0.6272, Validation Accuracy = 73.28%\n",
            "Epoch 57: Training Loss = 0.5897, Training Accuracy = 74.24%\n",
            "Epoch 57: Validation Loss = 0.6278, Validation Accuracy = 72.33%\n",
            "Epoch 58: Training Loss = 0.5850, Training Accuracy = 74.58%\n",
            "Epoch 58: Validation Loss = 0.6457, Validation Accuracy = 71.20%\n",
            "Epoch 59: Training Loss = 0.5808, Training Accuracy = 74.69%\n",
            "Epoch 59: Validation Loss = 0.6153, Validation Accuracy = 73.10%\n",
            "Epoch 60: Training Loss = 0.5836, Training Accuracy = 74.53%\n",
            "Epoch 60: Validation Loss = 0.6128, Validation Accuracy = 73.57%\n",
            "Epoch 61: Training Loss = 0.5827, Training Accuracy = 74.73%\n",
            "Epoch 61: Validation Loss = 0.6130, Validation Accuracy = 74.05%\n",
            "Epoch 62: Training Loss = 0.5814, Training Accuracy = 74.66%\n",
            "Epoch 62: Validation Loss = 0.6115, Validation Accuracy = 74.35%\n",
            "Epoch 63: Training Loss = 0.5768, Training Accuracy = 74.86%\n",
            "Epoch 63: Validation Loss = 0.6200, Validation Accuracy = 73.93%\n",
            "Epoch 64: Training Loss = 0.5738, Training Accuracy = 75.01%\n",
            "Epoch 64: Validation Loss = 0.6219, Validation Accuracy = 73.46%\n",
            "Epoch 65: Training Loss = 0.5735, Training Accuracy = 75.06%\n",
            "Epoch 65: Validation Loss = 0.6180, Validation Accuracy = 73.87%\n",
            "Epoch 66: Training Loss = 0.5735, Training Accuracy = 74.93%\n",
            "Epoch 66: Validation Loss = 0.6275, Validation Accuracy = 72.39%\n",
            "Epoch 67: Training Loss = 0.5701, Training Accuracy = 75.09%\n",
            "Epoch 67: Validation Loss = 0.6124, Validation Accuracy = 75.18%\n",
            "Epoch 68: Training Loss = 0.5664, Training Accuracy = 75.06%\n",
            "Epoch 68: Validation Loss = 0.6078, Validation Accuracy = 74.29%\n",
            "Epoch 69: Training Loss = 0.5667, Training Accuracy = 75.47%\n",
            "Epoch 69: Validation Loss = 0.6053, Validation Accuracy = 73.81%\n",
            "Epoch 70: Training Loss = 0.5637, Training Accuracy = 75.23%\n",
            "Epoch 70: Validation Loss = 0.6243, Validation Accuracy = 73.75%\n",
            "Epoch 71: Training Loss = 0.5640, Training Accuracy = 75.55%\n",
            "Epoch 71: Validation Loss = 0.6058, Validation Accuracy = 72.98%\n",
            "Epoch 72: Training Loss = 0.5604, Training Accuracy = 75.76%\n",
            "Epoch 72: Validation Loss = 0.6285, Validation Accuracy = 73.46%\n",
            "Epoch 73: Training Loss = 0.5622, Training Accuracy = 75.81%\n",
            "Epoch 73: Validation Loss = 0.6136, Validation Accuracy = 73.75%\n",
            "Epoch 74: Training Loss = 0.5570, Training Accuracy = 75.97%\n",
            "Epoch 74: Validation Loss = 0.6212, Validation Accuracy = 73.34%\n",
            "Epoch 75: Training Loss = 0.5518, Training Accuracy = 76.01%\n",
            "Epoch 75: Validation Loss = 0.6193, Validation Accuracy = 73.52%\n",
            "Epoch 76: Training Loss = 0.5541, Training Accuracy = 76.03%\n",
            "Epoch 76: Validation Loss = 0.6046, Validation Accuracy = 74.05%\n",
            "Epoch 77: Training Loss = 0.5597, Training Accuracy = 75.55%\n",
            "Epoch 77: Validation Loss = 0.6060, Validation Accuracy = 74.70%\n",
            "Epoch 78: Training Loss = 0.5516, Training Accuracy = 76.41%\n",
            "Epoch 78: Validation Loss = 0.6205, Validation Accuracy = 72.57%\n",
            "Epoch 79: Training Loss = 0.5489, Training Accuracy = 76.27%\n",
            "Epoch 79: Validation Loss = 0.6080, Validation Accuracy = 74.05%\n",
            "Epoch 80: Training Loss = 0.5522, Training Accuracy = 76.01%\n",
            "Epoch 80: Validation Loss = 0.6051, Validation Accuracy = 73.87%\n",
            "Epoch 81: Training Loss = 0.5458, Training Accuracy = 76.62%\n",
            "Epoch 81: Validation Loss = 0.6295, Validation Accuracy = 73.63%\n",
            "Epoch 82: Training Loss = 0.5457, Training Accuracy = 76.71%\n",
            "Epoch 82: Validation Loss = 0.6159, Validation Accuracy = 75.06%\n",
            "Epoch 83: Training Loss = 0.5455, Training Accuracy = 76.77%\n",
            "Epoch 83: Validation Loss = 0.6151, Validation Accuracy = 72.74%\n",
            "Epoch 84: Training Loss = 0.5414, Training Accuracy = 76.46%\n",
            "Epoch 84: Validation Loss = 0.6140, Validation Accuracy = 73.99%\n",
            "Epoch 85: Training Loss = 0.5383, Training Accuracy = 76.79%\n",
            "Epoch 85: Validation Loss = 0.6012, Validation Accuracy = 74.58%\n",
            "Epoch 86: Training Loss = 0.5377, Training Accuracy = 77.11%\n",
            "Epoch 86: Validation Loss = 0.6035, Validation Accuracy = 74.35%\n",
            "Epoch 87: Training Loss = 0.5353, Training Accuracy = 76.79%\n",
            "Epoch 87: Validation Loss = 0.6024, Validation Accuracy = 74.94%\n",
            "Epoch 88: Training Loss = 0.5355, Training Accuracy = 77.02%\n",
            "Epoch 88: Validation Loss = 0.6120, Validation Accuracy = 73.46%\n",
            "Epoch 89: Training Loss = 0.5361, Training Accuracy = 76.96%\n",
            "Epoch 89: Validation Loss = 0.5921, Validation Accuracy = 75.06%\n",
            "Epoch 90: Training Loss = 0.5318, Training Accuracy = 77.11%\n",
            "Epoch 90: Validation Loss = 0.6080, Validation Accuracy = 74.29%\n",
            "Epoch 91: Training Loss = 0.5310, Training Accuracy = 77.23%\n",
            "Epoch 91: Validation Loss = 0.5998, Validation Accuracy = 74.64%\n",
            "Epoch 92: Training Loss = 0.5272, Training Accuracy = 77.54%\n",
            "Epoch 92: Validation Loss = 0.6015, Validation Accuracy = 74.23%\n",
            "Epoch 93: Training Loss = 0.5211, Training Accuracy = 77.79%\n",
            "Epoch 93: Validation Loss = 0.5997, Validation Accuracy = 74.58%\n",
            "Epoch 94: Training Loss = 0.5238, Training Accuracy = 77.32%\n",
            "Epoch 94: Validation Loss = 0.5950, Validation Accuracy = 74.70%\n",
            "Epoch 95: Training Loss = 0.5224, Training Accuracy = 77.71%\n",
            "Epoch 95: Validation Loss = 0.5941, Validation Accuracy = 74.23%\n",
            "Epoch 96: Training Loss = 0.5160, Training Accuracy = 77.89%\n",
            "Epoch 96: Validation Loss = 0.6067, Validation Accuracy = 75.48%\n",
            "Epoch 97: Training Loss = 0.5203, Training Accuracy = 77.90%\n",
            "Epoch 97: Validation Loss = 0.6248, Validation Accuracy = 72.51%\n",
            "Epoch 98: Training Loss = 0.5174, Training Accuracy = 77.83%\n",
            "Epoch 98: Validation Loss = 0.6038, Validation Accuracy = 74.70%\n",
            "Epoch 99: Training Loss = 0.5167, Training Accuracy = 77.86%\n",
            "Epoch 99: Validation Loss = 0.6109, Validation Accuracy = 73.81%\n",
            "Epoch 100: Training Loss = 0.5154, Training Accuracy = 78.10%\n",
            "Epoch 100: Validation Loss = 0.6112, Validation Accuracy = 74.29%\n",
            "Epoch 101: Training Loss = 0.5151, Training Accuracy = 77.68%\n",
            "Epoch 101: Validation Loss = 0.6129, Validation Accuracy = 73.57%\n",
            "Epoch 102: Training Loss = 0.5151, Training Accuracy = 77.86%\n",
            "Epoch 102: Validation Loss = 0.5826, Validation Accuracy = 75.95%\n",
            "Epoch 103: Training Loss = 0.5143, Training Accuracy = 78.24%\n",
            "Epoch 103: Validation Loss = 0.6005, Validation Accuracy = 74.29%\n",
            "Epoch 104: Training Loss = 0.5125, Training Accuracy = 78.27%\n",
            "Epoch 104: Validation Loss = 0.6035, Validation Accuracy = 74.82%\n",
            "Epoch 105: Training Loss = 0.5034, Training Accuracy = 78.37%\n",
            "Epoch 105: Validation Loss = 0.6374, Validation Accuracy = 72.21%\n",
            "Epoch 106: Training Loss = 0.5062, Training Accuracy = 78.58%\n",
            "Epoch 106: Validation Loss = 0.6036, Validation Accuracy = 75.18%\n",
            "Epoch 107: Training Loss = 0.5024, Training Accuracy = 78.65%\n",
            "Epoch 107: Validation Loss = 0.5866, Validation Accuracy = 75.53%\n",
            "Epoch 108: Training Loss = 0.4988, Training Accuracy = 78.75%\n",
            "Epoch 108: Validation Loss = 0.5867, Validation Accuracy = 75.53%\n",
            "Epoch 109: Training Loss = 0.5032, Training Accuracy = 78.41%\n",
            "Epoch 109: Validation Loss = 0.5982, Validation Accuracy = 74.76%\n",
            "Epoch 110: Training Loss = 0.4963, Training Accuracy = 78.77%\n",
            "Epoch 110: Validation Loss = 0.6004, Validation Accuracy = 75.36%\n",
            "Epoch 111: Training Loss = 0.4993, Training Accuracy = 78.58%\n",
            "Epoch 111: Validation Loss = 0.5997, Validation Accuracy = 74.05%\n",
            "Epoch 112: Training Loss = 0.4968, Training Accuracy = 78.53%\n",
            "Epoch 112: Validation Loss = 0.6022, Validation Accuracy = 75.00%\n",
            "Epoch 113: Training Loss = 0.4938, Training Accuracy = 79.04%\n",
            "Epoch 113: Validation Loss = 0.5890, Validation Accuracy = 76.13%\n",
            "Epoch 114: Training Loss = 0.4880, Training Accuracy = 79.32%\n",
            "Epoch 114: Validation Loss = 0.6157, Validation Accuracy = 74.11%\n",
            "Epoch 115: Training Loss = 0.4899, Training Accuracy = 79.46%\n",
            "Epoch 115: Validation Loss = 0.5935, Validation Accuracy = 75.89%\n",
            "Epoch 116: Training Loss = 0.4909, Training Accuracy = 79.03%\n",
            "Epoch 116: Validation Loss = 0.6050, Validation Accuracy = 75.77%\n",
            "Epoch 117: Training Loss = 0.4899, Training Accuracy = 79.17%\n",
            "Epoch 117: Validation Loss = 0.5981, Validation Accuracy = 74.29%\n",
            "Epoch 118: Training Loss = 0.4886, Training Accuracy = 79.42%\n",
            "Epoch 118: Validation Loss = 0.5948, Validation Accuracy = 75.30%\n",
            "Epoch 119: Training Loss = 0.4836, Training Accuracy = 79.34%\n",
            "Epoch 119: Validation Loss = 0.6173, Validation Accuracy = 74.35%\n",
            "Epoch 120: Training Loss = 0.4846, Training Accuracy = 79.53%\n",
            "Epoch 120: Validation Loss = 0.5885, Validation Accuracy = 76.31%\n",
            "Epoch 121: Training Loss = 0.4812, Training Accuracy = 79.78%\n",
            "Epoch 121: Validation Loss = 0.6003, Validation Accuracy = 75.00%\n",
            "Epoch 122: Training Loss = 0.4818, Training Accuracy = 79.50%\n",
            "Epoch 122: Validation Loss = 0.6160, Validation Accuracy = 74.35%\n",
            "Epoch 123: Training Loss = 0.4774, Training Accuracy = 79.65%\n",
            "Epoch 123: Validation Loss = 0.6201, Validation Accuracy = 74.05%\n",
            "Epoch 124: Training Loss = 0.4785, Training Accuracy = 79.73%\n",
            "Epoch 124: Validation Loss = 0.5980, Validation Accuracy = 75.30%\n",
            "Epoch 125: Training Loss = 0.4756, Training Accuracy = 79.88%\n",
            "Epoch 125: Validation Loss = 0.5951, Validation Accuracy = 76.37%\n",
            "Epoch 126: Training Loss = 0.4750, Training Accuracy = 79.81%\n",
            "Epoch 126: Validation Loss = 0.5979, Validation Accuracy = 75.83%\n",
            "Epoch 127: Training Loss = 0.4762, Training Accuracy = 80.07%\n",
            "Epoch 127: Validation Loss = 0.5991, Validation Accuracy = 74.82%\n",
            "Epoch 128: Training Loss = 0.4725, Training Accuracy = 80.24%\n",
            "Epoch 128: Validation Loss = 0.6072, Validation Accuracy = 75.30%\n",
            "Epoch 129: Training Loss = 0.4711, Training Accuracy = 80.17%\n",
            "Epoch 129: Validation Loss = 0.6256, Validation Accuracy = 74.41%\n",
            "Epoch 130: Training Loss = 0.4667, Training Accuracy = 80.27%\n",
            "Epoch 130: Validation Loss = 0.6053, Validation Accuracy = 75.71%\n",
            "Epoch 131: Training Loss = 0.4643, Training Accuracy = 80.24%\n",
            "Epoch 131: Validation Loss = 0.6142, Validation Accuracy = 75.00%\n",
            "Epoch 132: Training Loss = 0.4644, Training Accuracy = 80.32%\n",
            "Epoch 132: Validation Loss = 0.5868, Validation Accuracy = 76.43%\n",
            "Epoch 133: Training Loss = 0.4618, Training Accuracy = 80.68%\n",
            "Epoch 133: Validation Loss = 0.6131, Validation Accuracy = 75.42%\n",
            "Epoch 134: Training Loss = 0.4651, Training Accuracy = 80.00%\n",
            "Epoch 134: Validation Loss = 0.6084, Validation Accuracy = 74.58%\n",
            "Epoch 135: Training Loss = 0.4639, Training Accuracy = 80.56%\n",
            "Epoch 135: Validation Loss = 0.6220, Validation Accuracy = 74.41%\n",
            "Epoch 136: Training Loss = 0.4592, Training Accuracy = 80.51%\n",
            "Epoch 136: Validation Loss = 0.5994, Validation Accuracy = 75.77%\n",
            "Epoch 137: Training Loss = 0.4558, Training Accuracy = 80.65%\n",
            "Epoch 137: Validation Loss = 0.5814, Validation Accuracy = 76.54%\n",
            "Epoch 138: Training Loss = 0.4545, Training Accuracy = 80.84%\n",
            "Epoch 138: Validation Loss = 0.6216, Validation Accuracy = 74.64%\n",
            "Epoch 139: Training Loss = 0.4535, Training Accuracy = 80.83%\n",
            "Epoch 139: Validation Loss = 0.5981, Validation Accuracy = 75.48%\n",
            "Epoch 140: Training Loss = 0.4525, Training Accuracy = 81.39%\n",
            "Epoch 140: Validation Loss = 0.6317, Validation Accuracy = 75.24%\n",
            "Epoch 141: Training Loss = 0.4536, Training Accuracy = 80.53%\n",
            "Epoch 141: Validation Loss = 0.5963, Validation Accuracy = 75.18%\n",
            "Epoch 142: Training Loss = 0.4454, Training Accuracy = 81.32%\n",
            "Epoch 142: Validation Loss = 0.6012, Validation Accuracy = 76.54%\n",
            "Epoch 143: Training Loss = 0.4444, Training Accuracy = 81.48%\n",
            "Epoch 143: Validation Loss = 0.6064, Validation Accuracy = 74.94%\n",
            "Epoch 144: Training Loss = 0.4454, Training Accuracy = 81.31%\n",
            "Epoch 144: Validation Loss = 0.5985, Validation Accuracy = 75.83%\n",
            "Epoch 145: Training Loss = 0.4426, Training Accuracy = 81.43%\n",
            "Epoch 145: Validation Loss = 0.5850, Validation Accuracy = 76.78%\n",
            "Epoch 146: Training Loss = 0.4445, Training Accuracy = 81.14%\n",
            "Epoch 146: Validation Loss = 0.5950, Validation Accuracy = 74.94%\n",
            "Epoch 147: Training Loss = 0.4445, Training Accuracy = 81.14%\n",
            "Epoch 147: Validation Loss = 0.6394, Validation Accuracy = 74.11%\n",
            "Epoch 148: Training Loss = 0.4451, Training Accuracy = 81.14%\n",
            "Epoch 148: Validation Loss = 0.6114, Validation Accuracy = 74.82%\n",
            "Epoch 149: Training Loss = 0.4389, Training Accuracy = 81.68%\n",
            "Epoch 149: Validation Loss = 0.6065, Validation Accuracy = 75.59%\n",
            "Epoch 150: Training Loss = 0.4328, Training Accuracy = 81.78%\n",
            "Epoch 150: Validation Loss = 0.6068, Validation Accuracy = 74.52%\n",
            "Epoch 151: Training Loss = 0.4350, Training Accuracy = 81.94%\n",
            "Epoch 151: Validation Loss = 0.6240, Validation Accuracy = 75.95%\n",
            "Epoch 152: Training Loss = 0.4384, Training Accuracy = 82.08%\n",
            "Epoch 152: Validation Loss = 0.5950, Validation Accuracy = 75.42%\n",
            "Epoch 153: Training Loss = 0.4360, Training Accuracy = 81.88%\n",
            "Epoch 153: Validation Loss = 0.5971, Validation Accuracy = 75.30%\n",
            "Epoch 154: Training Loss = 0.4362, Training Accuracy = 81.80%\n",
            "Epoch 154: Validation Loss = 0.6050, Validation Accuracy = 75.71%\n",
            "Epoch 155: Training Loss = 0.4307, Training Accuracy = 82.13%\n",
            "Epoch 155: Validation Loss = 0.6103, Validation Accuracy = 74.41%\n",
            "Epoch 156: Training Loss = 0.4305, Training Accuracy = 82.18%\n",
            "Epoch 156: Validation Loss = 0.6023, Validation Accuracy = 75.65%\n",
            "Epoch 157: Training Loss = 0.4246, Training Accuracy = 82.01%\n",
            "Epoch 157: Validation Loss = 0.6379, Validation Accuracy = 75.30%\n",
            "Epoch 158: Training Loss = 0.4245, Training Accuracy = 82.03%\n",
            "Epoch 158: Validation Loss = 0.6008, Validation Accuracy = 75.89%\n",
            "Epoch 159: Training Loss = 0.4226, Training Accuracy = 82.38%\n",
            "Epoch 159: Validation Loss = 0.6093, Validation Accuracy = 76.19%\n",
            "Epoch 160: Training Loss = 0.4233, Training Accuracy = 82.11%\n",
            "Epoch 160: Validation Loss = 0.6073, Validation Accuracy = 76.07%\n",
            "Epoch 161: Training Loss = 0.4190, Training Accuracy = 82.56%\n",
            "Epoch 161: Validation Loss = 0.6061, Validation Accuracy = 76.37%\n",
            "Epoch 162: Training Loss = 0.4216, Training Accuracy = 82.45%\n",
            "Epoch 162: Validation Loss = 0.5995, Validation Accuracy = 75.36%\n",
            "Epoch 163: Training Loss = 0.4168, Training Accuracy = 82.68%\n",
            "Epoch 163: Validation Loss = 0.6031, Validation Accuracy = 76.01%\n",
            "Epoch 164: Training Loss = 0.4168, Training Accuracy = 82.65%\n",
            "Epoch 164: Validation Loss = 0.6087, Validation Accuracy = 75.71%\n",
            "Epoch 165: Training Loss = 0.4171, Training Accuracy = 82.52%\n",
            "Epoch 165: Validation Loss = 0.6147, Validation Accuracy = 75.12%\n",
            "Epoch 166: Training Loss = 0.4123, Training Accuracy = 82.91%\n",
            "Epoch 166: Validation Loss = 0.5995, Validation Accuracy = 75.95%\n",
            "Epoch 167: Training Loss = 0.4130, Training Accuracy = 82.74%\n",
            "Epoch 167: Validation Loss = 0.6175, Validation Accuracy = 75.36%\n",
            "Epoch 168: Training Loss = 0.4149, Training Accuracy = 82.80%\n",
            "Epoch 168: Validation Loss = 0.6232, Validation Accuracy = 74.88%\n",
            "Epoch 169: Training Loss = 0.4119, Training Accuracy = 82.97%\n",
            "Epoch 169: Validation Loss = 0.6086, Validation Accuracy = 74.52%\n",
            "Epoch 170: Training Loss = 0.4057, Training Accuracy = 83.21%\n",
            "Epoch 170: Validation Loss = 0.6321, Validation Accuracy = 74.88%\n",
            "Epoch 171: Training Loss = 0.4117, Training Accuracy = 82.71%\n",
            "Epoch 171: Validation Loss = 0.5996, Validation Accuracy = 77.14%\n",
            "Epoch 172: Training Loss = 0.4041, Training Accuracy = 83.22%\n",
            "Epoch 172: Validation Loss = 0.6163, Validation Accuracy = 75.71%\n",
            "Epoch 173: Training Loss = 0.4040, Training Accuracy = 83.15%\n",
            "Epoch 173: Validation Loss = 0.6393, Validation Accuracy = 75.53%\n",
            "Epoch 174: Training Loss = 0.4004, Training Accuracy = 83.29%\n",
            "Epoch 174: Validation Loss = 0.6386, Validation Accuracy = 75.30%\n",
            "Epoch 175: Training Loss = 0.3999, Training Accuracy = 83.09%\n",
            "Epoch 175: Validation Loss = 0.6011, Validation Accuracy = 75.95%\n",
            "Epoch 176: Training Loss = 0.3994, Training Accuracy = 83.29%\n",
            "Epoch 176: Validation Loss = 0.6110, Validation Accuracy = 76.19%\n",
            "Epoch 177: Training Loss = 0.3965, Training Accuracy = 83.64%\n",
            "Epoch 177: Validation Loss = 0.6245, Validation Accuracy = 76.19%\n",
            "Epoch 178: Training Loss = 0.3997, Training Accuracy = 83.37%\n",
            "Epoch 178: Validation Loss = 0.6079, Validation Accuracy = 77.26%\n",
            "Epoch 179: Training Loss = 0.4004, Training Accuracy = 83.57%\n",
            "Epoch 179: Validation Loss = 0.6223, Validation Accuracy = 76.43%\n",
            "Epoch 180: Training Loss = 0.3945, Training Accuracy = 83.27%\n",
            "Epoch 180: Validation Loss = 0.6139, Validation Accuracy = 76.60%\n",
            "Epoch 181: Training Loss = 0.3943, Training Accuracy = 83.55%\n",
            "Epoch 181: Validation Loss = 0.6103, Validation Accuracy = 75.95%\n",
            "Epoch 182: Training Loss = 0.3921, Training Accuracy = 83.64%\n",
            "Epoch 182: Validation Loss = 0.6218, Validation Accuracy = 75.59%\n",
            "Epoch 183: Training Loss = 0.3882, Training Accuracy = 83.99%\n",
            "Epoch 183: Validation Loss = 0.6253, Validation Accuracy = 75.71%\n",
            "Epoch 184: Training Loss = 0.3952, Training Accuracy = 83.67%\n",
            "Epoch 184: Validation Loss = 0.5999, Validation Accuracy = 75.89%\n",
            "Epoch 185: Training Loss = 0.3903, Training Accuracy = 83.84%\n",
            "Epoch 185: Validation Loss = 0.6075, Validation Accuracy = 75.18%\n",
            "Epoch 186: Training Loss = 0.3896, Training Accuracy = 84.05%\n",
            "Epoch 186: Validation Loss = 0.6102, Validation Accuracy = 75.00%\n",
            "Epoch 187: Training Loss = 0.3825, Training Accuracy = 84.02%\n",
            "Epoch 187: Validation Loss = 0.6307, Validation Accuracy = 75.12%\n",
            "Epoch 188: Training Loss = 0.3798, Training Accuracy = 84.11%\n",
            "Epoch 188: Validation Loss = 0.6160, Validation Accuracy = 74.94%\n",
            "Epoch 189: Training Loss = 0.3858, Training Accuracy = 84.29%\n",
            "Epoch 189: Validation Loss = 0.6295, Validation Accuracy = 75.53%\n",
            "Epoch 190: Training Loss = 0.3838, Training Accuracy = 84.10%\n",
            "Epoch 190: Validation Loss = 0.6333, Validation Accuracy = 76.37%\n",
            "Epoch 191: Training Loss = 0.3780, Training Accuracy = 84.49%\n",
            "Epoch 191: Validation Loss = 0.6243, Validation Accuracy = 75.83%\n",
            "Epoch 192: Training Loss = 0.3832, Training Accuracy = 83.96%\n",
            "Epoch 192: Validation Loss = 0.6257, Validation Accuracy = 75.06%\n",
            "Epoch 193: Training Loss = 0.3769, Training Accuracy = 84.30%\n",
            "Epoch 193: Validation Loss = 0.6217, Validation Accuracy = 75.71%\n",
            "Epoch 194: Training Loss = 0.3769, Training Accuracy = 84.13%\n",
            "Epoch 194: Validation Loss = 0.6005, Validation Accuracy = 76.48%\n",
            "Epoch 195: Training Loss = 0.3681, Training Accuracy = 84.90%\n",
            "Epoch 195: Validation Loss = 0.6609, Validation Accuracy = 75.48%\n",
            "Epoch 196: Training Loss = 0.3727, Training Accuracy = 84.50%\n",
            "Epoch 196: Validation Loss = 0.6161, Validation Accuracy = 75.65%\n",
            "Epoch 197: Training Loss = 0.3760, Training Accuracy = 84.52%\n",
            "Epoch 197: Validation Loss = 0.6418, Validation Accuracy = 75.12%\n",
            "Epoch 198: Training Loss = 0.3742, Training Accuracy = 84.39%\n",
            "Epoch 198: Validation Loss = 0.6167, Validation Accuracy = 75.48%\n",
            "Epoch 199: Training Loss = 0.3646, Training Accuracy = 84.91%\n",
            "Epoch 199: Validation Loss = 0.6170, Validation Accuracy = 76.78%\n",
            "Epoch 200: Training Loss = 0.3630, Training Accuracy = 84.96%\n",
            "Epoch 200: Validation Loss = 0.6393, Validation Accuracy = 76.19%\n",
            "Evaluating on test set:\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.85      0.82      1060\n",
            "           1       0.27      0.03      0.05       105\n",
            "           2       0.76      0.55      0.64        98\n",
            "           3       0.62      0.65      0.63        82\n",
            "           4       0.63      0.78      0.69       116\n",
            "           5       0.65      0.69      0.67       104\n",
            "           6       0.75      0.79      0.77       117\n",
            "           7       0.20      0.67      0.31         3\n",
            "\n",
            "    accuracy                           0.75      1685\n",
            "   macro avg       0.59      0.62      0.57      1685\n",
            "weighted avg       0.73      0.75      0.73      1685\n",
            "\n",
            "Confusion Matrix:\n",
            "[[902   8  16  24  47  33  27   3]\n",
            " [100   3   0   0   0   1   0   1]\n",
            " [ 42   0  54   1   0   1   0   0]\n",
            " [ 24   0   0  53   0   1   4   0]\n",
            " [ 23   0   0   0  90   3   0   0]\n",
            " [ 27   0   0   0   5  72   0   0]\n",
            " [ 12   0   1   7   1   0  92   4]\n",
            " [  1   0   0   0   0   0   0   2]]\n"
          ]
        }
      ],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}